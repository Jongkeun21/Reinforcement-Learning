{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import random\n",
    "import gym\n",
    "import os\n",
    "\n",
    "from gridworld import gameEnv\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gameEnv(partial=False, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***QNetwork***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork() :\n",
    "    def __init__(self, h_size) :\n",
    "        self.scalarInput = tf.placeholder(shape=[None, 84*84*3], dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput, shape=[-1,84,84,3])\n",
    "        \n",
    "        self.conv1 = tf.contrib.layers.convolution2d(inputs=self.imageIn, num_outputs=32, kernel_size=[8,8], stride=[4,4], padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = tf.contrib.layers.convolution2d(inputs=self.conv1, num_outputs=64, kernel_size=[4,4], stride=[2,2], padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = tf.contrib.layers.convolution2d(inputs=self.conv2, num_outputs=64, kernel_size=[3,3], stride=[1,1], padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = tf.contrib.layers.convolution2d(inputs=self.conv3, num_outputs=h_size, kernel_size=[7,7], stride=[1,1], padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        self.streamAC, self.streamVC = tf.split(self.conv4, 2, 3)\n",
    "        self.streamA = tf.contrib.layers.flatten(self.streamAC)\n",
    "        self.streamV = tf.contrib.layers.flatten(self.streamVC)\n",
    "        \n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2, env.actions]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2, 1]))\n",
    "        \n",
    "        self.Advantage = tf.matmul(self.streamA, self.AW)\n",
    "        self.Value = tf.matmul(self.streamV, self.VW)\n",
    "        \n",
    "        self.QOut = self.Value + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage, axis=1, keep_dims=True))\n",
    "        self.predict = tf.argmax(self.QOut, 1)\n",
    "        \n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        \n",
    "        self.actions_onehot = tf.one_hot(self.actions, env.actions, dtype=tf.float32)\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.QOut, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ-self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Experience replay***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience_buffer() :\n",
    "    def __init__(self, buffer_size=1000) :\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "    def add(self, experience) :\n",
    "        if len(self.buffer)+len(experience) >= self.buffer_size :\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "            \n",
    "        self.buffer.extend(experience)\n",
    "        \n",
    "    def sample(self, size) :\n",
    "        return np.reshape(np.array(random.sample(self.buffer, size)), [size, 5])\n",
    "    \n",
    "def processState(states) :\n",
    "    return np.reshape(states, [84*84*3])\n",
    "\n",
    "def updateTargetGraph(tfVars, tau) :\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    \n",
    "    for idx, var in enumerate(tfVars[0:total_vars//2]) :\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau)+((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "        \n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder, sess) :\n",
    "    for op in op_holder :\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Training***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "update_freq = 4\n",
    "y = 0.99    # discounting factor\n",
    "startE = 1\n",
    "endE = 0.1\n",
    "annealing_step = 1000.    # How many steps of training to reduce startE to endE\n",
    "num_episodes = 1000\n",
    "pre_train_steps = 1000\n",
    "max_epLength = 50    # The max allowed length of episode\n",
    "load_model = False\n",
    "path = './dqn'\n",
    "h_size = 512\n",
    "tau = 1e-3    # Rate to update target newtork toward primary network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "======================================\n",
      "Percent:  16.082  %\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(h_size)\n",
    "targetQN = QNetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "trainable = tf.trainable_variables()\n",
    "targetOps = updateTargetGraph(trainable, tau)\n",
    "myBuffer = Experience_buffer()\n",
    "\n",
    "e = startE\n",
    "stepDrop = (startE-endE)/annealing_step    # decaying epsilon to endE\n",
    "\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "if not os.path.exists(path) :\n",
    "    os.mkdir(path)\n",
    "    \n",
    "with tf.Session() as sess :\n",
    "    if load_model :\n",
    "        print('Loading...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "    sess.run(init)\n",
    "    updateTarget(targetOps, sess)\n",
    "    \n",
    "    for i in range(num_episodes) :\n",
    "        episodeBuffer = Experience_buffer()\n",
    "        \n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        \n",
    "        while j < max_epLength :\n",
    "            j += 1\n",
    "            \n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps :\n",
    "                a = np.random.randint(0, 4)\n",
    "            else :\n",
    "                a = sess.run(mainQN.predict, feed_dict={mainQN.scalarInput: [s]})[0]\n",
    "                \n",
    "            s1, r, d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]), [1,5]))\n",
    "            \n",
    "            if total_steps > pre_train_steps :\n",
    "                if e > endE :\n",
    "                    e -= stepDrop\n",
    "                    \n",
    "                if total_steps % (update_freq) == 0 :\n",
    "                    trainBatch = myBuffer.sample(batch_size)\n",
    "                    \n",
    "                    Q1 = sess.run(mainQN.predict, feed_dict={mainQN.scalarInput: np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.QOut, feed_dict={targetQN.scalarInput: np.vstack(trainBatch[:,3])})\n",
    "                    \n",
    "                    end_multiplier = -(trainBatch[:,4]-1)\n",
    "                    doubleQ = Q2[range(batch_size), Q1]\n",
    "                    targetQ = trainBatch[:,2]+(y*doubleQ*end_multiplier)\n",
    "                    \n",
    "                    _ = sess.run(mainQN.updateModel, feed_dict={mainQN.scalarInput: np.vstack(trainBatch[:,0]), mainQN.targetQ: targetQ, mainQN.actions: trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps, sess)\n",
    "                    \n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d :\n",
    "                break\n",
    "                \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        \n",
    "        if i%100 == 0 :\n",
    "            saver.save(sess, path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"======================================\")\n",
    "            \n",
    "    saver.save(sess, path+'/model-'+str(i)+'.ckpt')\n",
    "    \n",
    "print('Percent: ', sum(rList)/num_episodes, ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
