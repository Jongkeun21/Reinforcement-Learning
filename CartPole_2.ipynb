{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole_Deep Q-Network_Nature 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as ran\n",
    "import gym\n",
    "\n",
    "from gym import wrappers\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLAY = 10\n",
    "REPLAYLIST = []\n",
    "MINIBATCH = 10\n",
    "CAPACITY = 500\n",
    "lr = 1e-3\n",
    "df = 0.99\n",
    "dp = 1\n",
    "path = \"save/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = env.observation_space.shape[0]\n",
    "OUTPUT = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[None,INPUT], dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None,OUTPUT], dtype=tf.float32)\n",
    "dropout = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Main Network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "W1 = tf.get_variable(shape=[INPUT,32], name='W1', initializer=xavier)\n",
    "W2 = tf.get_variable(shape=[32,64], name='W2', initializer=xavier)\n",
    "W3 = tf.get_variable(shape=[64,64], name='W3', initializer=xavier)\n",
    "W4 = tf.get_variable(shape=[64,OUTPUT], name='W4', initializer=xavier)\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "b3 = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(x, W1)+b1)\n",
    "L1 = tf.nn.dropout(L1, dropout)\n",
    "\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2)+b2)\n",
    "L2 = tf.nn.dropout(L2, dropout)\n",
    "\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3)+b3)\n",
    "L3 = tf.nn.dropout(L3, dropout)\n",
    "\n",
    "Q_ = tf.matmul(L3, W4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Target Network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_ = tf.get_variable(shape=[INPUT,32], name='W1_')\n",
    "W2_ = tf.get_variable(shape=[32,64], name='W2_')\n",
    "W3_ = tf.get_variable(shape=[64,64], name='W3_')\n",
    "W4_ = tf.get_variable(shape=[64,OUTPUT], name='W4_')\n",
    "\n",
    "b1_ = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "b2_ = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "b3_ = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "\n",
    "L1_ = tf.nn.relu(tf.matmul(x, W1_)+b1_)\n",
    "L2_ = tf.nn.relu(tf.matmul(L1_, W2_)+b2_)\n",
    "L3_ = tf.nn.relu(tf.matmul(L2_, W3_)+b3_)\n",
    "\n",
    "Q_r = tf.matmul(L3_, W4_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rList = [0]\n",
    "recent_rList = [0]\n",
    "episode = 0\n",
    "num_episodes = 1000\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(y-Q_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, epsilon=1e-1)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.9394706\n",
      "Episode: 1, steps: 46, reward: 46.0, average: 23.0, recent: 23.0\n",
      "Episode: 2, steps: 13, reward: 13.0, average: 19.666666666666668, recent: 19.666666666666668\n",
      "Episode: 3, steps: 17, reward: 17.0, average: 19.0, recent: 19.0\n",
      "Episode: 4, steps: 20, reward: 20.0, average: 19.2, recent: 19.2\n",
      "Episode: 5, steps: 25, reward: 25.0, average: 20.166666666666668, recent: 20.166666666666668\n",
      "Episode: 6, steps: 14, reward: 14.0, average: 19.285714285714285, recent: 19.285714285714285\n",
      "Episode: 7, steps: 15, reward: 15.0, average: 18.75, recent: 18.75\n",
      "Episode: 8, steps: 16, reward: 16.0, average: 18.444444444444443, recent: 18.444444444444443\n",
      "Episode: 9, steps: 12, reward: 12.0, average: 17.8, recent: 17.8\n",
      "Episode: 10, steps: 43, reward: 43.0, average: 20.09090909090909, recent: 20.09090909090909\n",
      "loss:  1.0815161\n",
      "Episode: 11, steps: 16, reward: 16.0, average: 19.75, recent: 19.75\n",
      "Episode: 12, steps: 10, reward: 10.0, average: 19.0, recent: 19.0\n",
      "Episode: 13, steps: 13, reward: 13.0, average: 18.571428571428573, recent: 18.571428571428573\n",
      "Episode: 14, steps: 17, reward: 17.0, average: 18.466666666666665, recent: 18.466666666666665\n",
      "Episode: 15, steps: 13, reward: 13.0, average: 18.125, recent: 18.125\n",
      "Episode: 16, steps: 9, reward: 9.0, average: 17.58823529411765, recent: 17.58823529411765\n",
      "Episode: 17, steps: 14, reward: 14.0, average: 17.38888888888889, recent: 17.38888888888889\n",
      "Episode: 18, steps: 16, reward: 16.0, average: 17.31578947368421, recent: 17.31578947368421\n",
      "Episode: 19, steps: 31, reward: 31.0, average: 18.0, recent: 18.0\n",
      "Episode: 20, steps: 14, reward: 14.0, average: 17.80952380952381, recent: 17.80952380952381\n",
      "loss:  1.0205219\n",
      "Episode: 21, steps: 10, reward: 10.0, average: 17.454545454545453, recent: 17.454545454545453\n",
      "Episode: 22, steps: 15, reward: 15.0, average: 17.347826086956523, recent: 17.347826086956523\n",
      "Episode: 23, steps: 12, reward: 12.0, average: 17.125, recent: 17.125\n",
      "Episode: 24, steps: 11, reward: 11.0, average: 16.88, recent: 16.88\n",
      "Episode: 25, steps: 11, reward: 11.0, average: 16.653846153846153, recent: 16.653846153846153\n",
      "Episode: 26, steps: 12, reward: 12.0, average: 16.48148148148148, recent: 16.48148148148148\n",
      "Episode: 27, steps: 13, reward: 13.0, average: 16.357142857142858, recent: 16.357142857142858\n",
      "Episode: 28, steps: 17, reward: 17.0, average: 16.379310344827587, recent: 16.379310344827587\n",
      "Episode: 29, steps: 13, reward: 13.0, average: 16.266666666666666, recent: 16.266666666666666\n",
      "Episode: 30, steps: 9, reward: 9.0, average: 16.032258064516128, recent: 16.032258064516128\n",
      "loss:  1.1756314\n",
      "Episode: 31, steps: 10, reward: 10.0, average: 15.84375, recent: 15.84375\n",
      "Episode: 32, steps: 8, reward: 8.0, average: 15.606060606060606, recent: 15.606060606060606\n",
      "Episode: 33, steps: 10, reward: 10.0, average: 15.441176470588236, recent: 15.441176470588236\n",
      "Episode: 34, steps: 10, reward: 10.0, average: 15.285714285714286, recent: 15.285714285714286\n",
      "Episode: 35, steps: 12, reward: 12.0, average: 15.194444444444445, recent: 15.194444444444445\n",
      "Episode: 36, steps: 15, reward: 15.0, average: 15.18918918918919, recent: 15.18918918918919\n",
      "Episode: 37, steps: 10, reward: 10.0, average: 15.052631578947368, recent: 15.052631578947368\n",
      "Episode: 38, steps: 13, reward: 13.0, average: 15.0, recent: 15.0\n",
      "Episode: 39, steps: 11, reward: 11.0, average: 14.9, recent: 14.9\n",
      "Episode: 40, steps: 12, reward: 12.0, average: 14.829268292682928, recent: 14.829268292682928\n",
      "loss:  1.0653366\n",
      "Episode: 41, steps: 11, reward: 11.0, average: 14.738095238095237, recent: 14.738095238095237\n",
      "Episode: 42, steps: 12, reward: 12.0, average: 14.674418604651162, recent: 14.674418604651162\n",
      "Episode: 43, steps: 16, reward: 16.0, average: 14.704545454545455, recent: 14.704545454545455\n",
      "Episode: 44, steps: 9, reward: 9.0, average: 14.577777777777778, recent: 14.577777777777778\n",
      "Episode: 45, steps: 24, reward: 24.0, average: 14.782608695652174, recent: 14.782608695652174\n",
      "Episode: 46, steps: 10, reward: 10.0, average: 14.680851063829786, recent: 14.680851063829786\n",
      "Episode: 47, steps: 9, reward: 9.0, average: 14.5625, recent: 14.5625\n",
      "Episode: 48, steps: 19, reward: 19.0, average: 14.653061224489797, recent: 14.653061224489797\n",
      "Episode: 49, steps: 12, reward: 12.0, average: 14.6, recent: 14.6\n",
      "Episode: 50, steps: 11, reward: 11.0, average: 14.529411764705882, recent: 14.529411764705882\n",
      "loss:  1.0707756\n",
      "Episode: 51, steps: 13, reward: 13.0, average: 14.5, recent: 14.5\n",
      "Episode: 52, steps: 11, reward: 11.0, average: 14.433962264150944, recent: 14.433962264150944\n",
      "Episode: 53, steps: 9, reward: 9.0, average: 14.333333333333334, recent: 14.333333333333334\n",
      "Episode: 54, steps: 13, reward: 13.0, average: 14.309090909090909, recent: 14.309090909090909\n",
      "Episode: 55, steps: 14, reward: 14.0, average: 14.303571428571429, recent: 14.303571428571429\n",
      "Episode: 56, steps: 10, reward: 10.0, average: 14.228070175438596, recent: 14.228070175438596\n",
      "Episode: 57, steps: 10, reward: 10.0, average: 14.155172413793103, recent: 14.155172413793103\n",
      "Episode: 58, steps: 9, reward: 9.0, average: 14.067796610169491, recent: 14.067796610169491\n",
      "Episode: 59, steps: 10, reward: 10.0, average: 14.0, recent: 14.0\n",
      "Episode: 60, steps: 10, reward: 10.0, average: 13.934426229508198, recent: 13.934426229508198\n",
      "loss:  1.2535316\n",
      "Episode: 61, steps: 21, reward: 21.0, average: 14.048387096774194, recent: 14.048387096774194\n",
      "Episode: 62, steps: 14, reward: 14.0, average: 14.047619047619047, recent: 14.047619047619047\n",
      "Episode: 63, steps: 12, reward: 12.0, average: 14.015625, recent: 14.015625\n",
      "Episode: 64, steps: 13, reward: 13.0, average: 14.0, recent: 14.0\n",
      "Episode: 65, steps: 12, reward: 12.0, average: 13.969696969696969, recent: 13.969696969696969\n",
      "Episode: 66, steps: 12, reward: 12.0, average: 13.940298507462687, recent: 13.940298507462687\n",
      "Episode: 67, steps: 11, reward: 11.0, average: 13.897058823529411, recent: 13.897058823529411\n",
      "Episode: 68, steps: 11, reward: 11.0, average: 13.855072463768115, recent: 13.855072463768115\n",
      "Episode: 69, steps: 11, reward: 11.0, average: 13.814285714285715, recent: 13.814285714285715\n",
      "Episode: 70, steps: 11, reward: 11.0, average: 13.774647887323944, recent: 13.774647887323944\n",
      "loss:  1.0509161\n",
      "Episode: 71, steps: 10, reward: 10.0, average: 13.722222222222221, recent: 13.722222222222221\n",
      "Episode: 72, steps: 13, reward: 13.0, average: 13.712328767123287, recent: 13.712328767123287\n",
      "Episode: 73, steps: 13, reward: 13.0, average: 13.702702702702704, recent: 13.702702702702704\n",
      "Episode: 74, steps: 10, reward: 10.0, average: 13.653333333333334, recent: 13.653333333333334\n",
      "Episode: 75, steps: 8, reward: 8.0, average: 13.578947368421053, recent: 13.578947368421053\n",
      "Episode: 76, steps: 10, reward: 10.0, average: 13.532467532467532, recent: 13.532467532467532\n",
      "Episode: 77, steps: 9, reward: 9.0, average: 13.474358974358974, recent: 13.474358974358974\n",
      "Episode: 78, steps: 10, reward: 10.0, average: 13.430379746835444, recent: 13.430379746835444\n",
      "Episode: 79, steps: 10, reward: 10.0, average: 13.3875, recent: 13.3875\n",
      "Episode: 80, steps: 13, reward: 13.0, average: 13.382716049382717, recent: 13.382716049382717\n",
      "loss:  1.0052786\n",
      "Episode: 81, steps: 11, reward: 11.0, average: 13.353658536585366, recent: 13.353658536585366\n",
      "Episode: 82, steps: 12, reward: 12.0, average: 13.337349397590362, recent: 13.337349397590362\n",
      "Episode: 83, steps: 9, reward: 9.0, average: 13.285714285714286, recent: 13.285714285714286\n",
      "Episode: 84, steps: 19, reward: 19.0, average: 13.352941176470589, recent: 13.352941176470589\n",
      "Episode: 85, steps: 10, reward: 10.0, average: 13.313953488372093, recent: 13.313953488372093\n",
      "Episode: 86, steps: 11, reward: 11.0, average: 13.28735632183908, recent: 13.28735632183908\n",
      "Episode: 87, steps: 17, reward: 17.0, average: 13.329545454545455, recent: 13.329545454545455\n",
      "Episode: 88, steps: 10, reward: 10.0, average: 13.292134831460674, recent: 13.292134831460674\n",
      "Episode: 89, steps: 10, reward: 10.0, average: 13.255555555555556, recent: 13.255555555555556\n",
      "Episode: 90, steps: 9, reward: 9.0, average: 13.208791208791208, recent: 13.208791208791208\n",
      "loss:  1.2135028\n",
      "Episode: 91, steps: 8, reward: 8.0, average: 13.152173913043478, recent: 13.152173913043478\n",
      "Episode: 92, steps: 9, reward: 9.0, average: 13.10752688172043, recent: 13.10752688172043\n",
      "Episode: 93, steps: 12, reward: 12.0, average: 13.095744680851064, recent: 13.095744680851064\n",
      "Episode: 94, steps: 8, reward: 8.0, average: 13.042105263157895, recent: 13.042105263157895\n",
      "Episode: 95, steps: 13, reward: 13.0, average: 13.041666666666666, recent: 13.041666666666666\n",
      "Episode: 96, steps: 13, reward: 13.0, average: 13.041237113402062, recent: 13.041237113402062\n",
      "Episode: 97, steps: 10, reward: 10.0, average: 13.010204081632653, recent: 13.010204081632653\n",
      "Episode: 98, steps: 12, reward: 12.0, average: 13.0, recent: 13.0\n",
      "Episode: 99, steps: 10, reward: 10.0, average: 12.97, recent: 12.97\n",
      "Episode: 100, steps: 11, reward: 11.0, average: 12.950495049504951, recent: 12.950495049504951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.1885016\n",
      "Episode: 101, steps: 8, reward: 8.0, average: 12.901960784313726, recent: 12.901960784313726\n",
      "Episode: 102, steps: 9, reward: 9.0, average: 12.864077669902912, recent: 12.864077669902912\n",
      "Episode: 103, steps: 9, reward: 9.0, average: 12.826923076923077, recent: 12.826923076923077\n",
      "Episode: 104, steps: 11, reward: 11.0, average: 12.80952380952381, recent: 12.80952380952381\n",
      "Episode: 105, steps: 9, reward: 9.0, average: 12.773584905660377, recent: 12.773584905660377\n",
      "Episode: 106, steps: 12, reward: 12.0, average: 12.766355140186915, recent: 12.766355140186915\n",
      "Episode: 107, steps: 10, reward: 10.0, average: 12.74074074074074, recent: 12.74074074074074\n",
      "Episode: 108, steps: 9, reward: 9.0, average: 12.706422018348624, recent: 12.706422018348624\n",
      "Episode: 109, steps: 11, reward: 11.0, average: 12.690909090909091, recent: 12.690909090909091\n",
      "Episode: 110, steps: 11, reward: 11.0, average: 12.675675675675675, recent: 12.675675675675675\n",
      "loss:  1.617532\n",
      "Episode: 111, steps: 10, reward: 10.0, average: 12.651785714285714, recent: 12.651785714285714\n",
      "Episode: 112, steps: 9, reward: 9.0, average: 12.619469026548673, recent: 12.619469026548673\n",
      "Episode: 113, steps: 9, reward: 9.0, average: 12.587719298245615, recent: 12.587719298245615\n",
      "Episode: 114, steps: 12, reward: 12.0, average: 12.582608695652175, recent: 12.582608695652175\n",
      "Episode: 115, steps: 11, reward: 11.0, average: 12.568965517241379, recent: 12.568965517241379\n",
      "Episode: 116, steps: 10, reward: 10.0, average: 12.547008547008547, recent: 12.547008547008547\n",
      "Episode: 117, steps: 8, reward: 8.0, average: 12.508474576271187, recent: 12.508474576271187\n",
      "Episode: 118, steps: 10, reward: 10.0, average: 12.487394957983193, recent: 12.487394957983193\n",
      "Episode: 119, steps: 10, reward: 10.0, average: 12.466666666666667, recent: 12.466666666666667\n",
      "Episode: 120, steps: 10, reward: 10.0, average: 12.446280991735538, recent: 12.446280991735538\n",
      "loss:  1.073438\n",
      "Episode: 121, steps: 10, reward: 10.0, average: 12.426229508196721, recent: 12.426229508196721\n",
      "Episode: 122, steps: 10, reward: 10.0, average: 12.40650406504065, recent: 12.40650406504065\n",
      "Episode: 123, steps: 11, reward: 11.0, average: 12.39516129032258, recent: 12.39516129032258\n",
      "Episode: 124, steps: 10, reward: 10.0, average: 12.376, recent: 12.376\n",
      "Episode: 125, steps: 8, reward: 8.0, average: 12.341269841269842, recent: 12.341269841269842\n",
      "Episode: 126, steps: 9, reward: 9.0, average: 12.31496062992126, recent: 12.31496062992126\n",
      "Episode: 127, steps: 10, reward: 10.0, average: 12.296875, recent: 12.296875\n",
      "Episode: 128, steps: 8, reward: 8.0, average: 12.263565891472869, recent: 12.263565891472869\n",
      "Episode: 129, steps: 9, reward: 9.0, average: 12.238461538461538, recent: 12.238461538461538\n",
      "Episode: 130, steps: 9, reward: 9.0, average: 12.213740458015268, recent: 12.213740458015268\n",
      "loss:  4.160922\n",
      "Episode: 131, steps: 9, reward: 9.0, average: 12.18939393939394, recent: 12.18939393939394\n",
      "Episode: 132, steps: 8, reward: 8.0, average: 12.157894736842104, recent: 12.157894736842104\n",
      "Episode: 133, steps: 10, reward: 10.0, average: 12.14179104477612, recent: 12.14179104477612\n",
      "Episode: 134, steps: 11, reward: 11.0, average: 12.133333333333333, recent: 12.133333333333333\n",
      "Episode: 135, steps: 9, reward: 9.0, average: 12.110294117647058, recent: 12.110294117647058\n",
      "Episode: 136, steps: 9, reward: 9.0, average: 12.087591240875913, recent: 12.087591240875913\n",
      "Episode: 137, steps: 10, reward: 10.0, average: 12.072463768115941, recent: 12.072463768115941\n",
      "Episode: 138, steps: 8, reward: 8.0, average: 12.043165467625899, recent: 12.043165467625899\n",
      "Episode: 139, steps: 13, reward: 13.0, average: 12.05, recent: 12.05\n",
      "Episode: 140, steps: 9, reward: 9.0, average: 12.02836879432624, recent: 12.02836879432624\n",
      "loss:  5.4461575\n",
      "Episode: 141, steps: 14, reward: 14.0, average: 12.04225352112676, recent: 12.04225352112676\n",
      "Episode: 142, steps: 10, reward: 10.0, average: 12.027972027972028, recent: 12.027972027972028\n",
      "Episode: 143, steps: 12, reward: 12.0, average: 12.027777777777779, recent: 12.027777777777779\n",
      "Episode: 144, steps: 10, reward: 10.0, average: 12.013793103448275, recent: 12.013793103448275\n",
      "Episode: 145, steps: 9, reward: 9.0, average: 11.993150684931507, recent: 11.993150684931507\n",
      "Episode: 146, steps: 8, reward: 8.0, average: 11.965986394557824, recent: 11.965986394557824\n",
      "Episode: 147, steps: 10, reward: 10.0, average: 11.952702702702704, recent: 11.952702702702704\n",
      "Episode: 148, steps: 9, reward: 9.0, average: 11.93288590604027, recent: 11.93288590604027\n",
      "Episode: 149, steps: 11, reward: 11.0, average: 11.926666666666666, recent: 11.926666666666666\n",
      "Episode: 150, steps: 11, reward: 11.0, average: 11.920529801324504, recent: 11.920529801324504\n",
      "loss:  2.720315\n",
      "Episode: 151, steps: 10, reward: 10.0, average: 11.907894736842104, recent: 11.907894736842104\n",
      "Episode: 152, steps: 12, reward: 12.0, average: 11.908496732026144, recent: 11.908496732026144\n",
      "Episode: 153, steps: 9, reward: 9.0, average: 11.88961038961039, recent: 11.88961038961039\n",
      "Episode: 154, steps: 9, reward: 9.0, average: 11.870967741935484, recent: 11.870967741935484\n",
      "Episode: 155, steps: 10, reward: 10.0, average: 11.85897435897436, recent: 11.85897435897436\n",
      "Episode: 156, steps: 9, reward: 9.0, average: 11.840764331210192, recent: 11.840764331210192\n",
      "Episode: 157, steps: 9, reward: 9.0, average: 11.822784810126583, recent: 11.822784810126583\n",
      "Episode: 158, steps: 9, reward: 9.0, average: 11.80503144654088, recent: 11.80503144654088\n",
      "Episode: 159, steps: 10, reward: 10.0, average: 11.79375, recent: 11.79375\n",
      "Episode: 160, steps: 9, reward: 9.0, average: 11.77639751552795, recent: 11.77639751552795\n",
      "loss:  4.9981503\n",
      "Episode: 161, steps: 9, reward: 9.0, average: 11.75925925925926, recent: 11.75925925925926\n",
      "Episode: 162, steps: 10, reward: 10.0, average: 11.748466257668712, recent: 11.748466257668712\n",
      "Episode: 163, steps: 9, reward: 9.0, average: 11.731707317073171, recent: 11.731707317073171\n",
      "Episode: 164, steps: 10, reward: 10.0, average: 11.72121212121212, recent: 11.72121212121212\n",
      "Episode: 165, steps: 10, reward: 10.0, average: 11.710843373493976, recent: 11.710843373493976\n",
      "Episode: 166, steps: 9, reward: 9.0, average: 11.694610778443113, recent: 11.694610778443113\n",
      "Episode: 167, steps: 11, reward: 11.0, average: 11.69047619047619, recent: 11.69047619047619\n",
      "Episode: 168, steps: 10, reward: 10.0, average: 11.680473372781066, recent: 11.680473372781066\n",
      "Episode: 169, steps: 12, reward: 12.0, average: 11.68235294117647, recent: 11.68235294117647\n",
      "Episode: 170, steps: 9, reward: 9.0, average: 11.666666666666666, recent: 11.666666666666666\n",
      "loss:  5.715269\n",
      "Episode: 171, steps: 10, reward: 10.0, average: 11.656976744186046, recent: 11.656976744186046\n",
      "Episode: 172, steps: 12, reward: 12.0, average: 11.658959537572255, recent: 11.658959537572255\n",
      "Episode: 173, steps: 10, reward: 10.0, average: 11.649425287356323, recent: 11.649425287356323\n",
      "Episode: 174, steps: 12, reward: 12.0, average: 11.651428571428571, recent: 11.651428571428571\n",
      "Episode: 175, steps: 14, reward: 14.0, average: 11.664772727272727, recent: 11.664772727272727\n",
      "Episode: 176, steps: 11, reward: 11.0, average: 11.661016949152541, recent: 11.661016949152541\n",
      "Episode: 177, steps: 10, reward: 10.0, average: 11.651685393258427, recent: 11.651685393258427\n",
      "Episode: 178, steps: 10, reward: 10.0, average: 11.64245810055866, recent: 11.64245810055866\n",
      "Episode: 179, steps: 11, reward: 11.0, average: 11.63888888888889, recent: 11.63888888888889\n",
      "Episode: 180, steps: 11, reward: 11.0, average: 11.6353591160221, recent: 11.6353591160221\n",
      "loss:  7.737011\n",
      "Episode: 181, steps: 10, reward: 10.0, average: 11.626373626373626, recent: 11.626373626373626\n",
      "Episode: 182, steps: 11, reward: 11.0, average: 11.62295081967213, recent: 11.62295081967213\n",
      "Episode: 183, steps: 10, reward: 10.0, average: 11.61413043478261, recent: 11.61413043478261\n",
      "Episode: 184, steps: 10, reward: 10.0, average: 11.605405405405405, recent: 11.605405405405405\n",
      "Episode: 185, steps: 9, reward: 9.0, average: 11.591397849462366, recent: 11.591397849462366\n",
      "Episode: 186, steps: 8, reward: 8.0, average: 11.572192513368984, recent: 11.572192513368984\n",
      "Episode: 187, steps: 8, reward: 8.0, average: 11.553191489361701, recent: 11.553191489361701\n",
      "Episode: 188, steps: 10, reward: 10.0, average: 11.544973544973544, recent: 11.544973544973544\n",
      "Episode: 189, steps: 11, reward: 11.0, average: 11.542105263157895, recent: 11.542105263157895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 190, steps: 10, reward: 10.0, average: 11.534031413612565, recent: 11.534031413612565\n",
      "loss:  9.815416\n",
      "Episode: 191, steps: 10, reward: 10.0, average: 11.526041666666666, recent: 11.526041666666666\n",
      "Episode: 192, steps: 10, reward: 10.0, average: 11.518134715025907, recent: 11.518134715025907\n",
      "Episode: 193, steps: 10, reward: 10.0, average: 11.510309278350515, recent: 11.510309278350515\n",
      "Episode: 194, steps: 13, reward: 13.0, average: 11.517948717948718, recent: 11.517948717948718\n",
      "Episode: 195, steps: 12, reward: 12.0, average: 11.520408163265307, recent: 11.520408163265307\n",
      "Episode: 196, steps: 9, reward: 9.0, average: 11.50761421319797, recent: 11.50761421319797\n",
      "Episode: 197, steps: 10, reward: 10.0, average: 11.5, recent: 11.5\n",
      "Episode: 198, steps: 10, reward: 10.0, average: 11.492462311557789, recent: 11.492462311557789\n",
      "Episode: 199, steps: 9, reward: 9.0, average: 11.48, recent: 11.48\n",
      "Episode: 200, steps: 10, reward: 10.0, average: 11.472636815920398, recent: 11.472636815920398\n",
      "loss:  4.9440975\n",
      "Episode: 201, steps: 17, reward: 17.0, average: 11.5, recent: 11.557213930348258\n",
      "Episode: 202, steps: 11, reward: 11.0, average: 11.497536945812808, recent: 11.383084577114428\n",
      "Episode: 203, steps: 11, reward: 11.0, average: 11.495098039215685, recent: 11.373134328358208\n",
      "Episode: 204, steps: 9, reward: 9.0, average: 11.482926829268292, recent: 11.333333333333334\n",
      "Episode: 205, steps: 9, reward: 9.0, average: 11.470873786407767, recent: 11.278606965174129\n",
      "Episode: 206, steps: 10, reward: 10.0, average: 11.46376811594203, recent: 11.203980099502488\n",
      "Episode: 207, steps: 9, reward: 9.0, average: 11.451923076923077, recent: 11.17910447761194\n",
      "Episode: 208, steps: 14, reward: 14.0, average: 11.464114832535886, recent: 11.17412935323383\n",
      "Episode: 209, steps: 8, reward: 8.0, average: 11.447619047619048, recent: 11.134328358208956\n",
      "Episode: 210, steps: 11, reward: 11.0, average: 11.445497630331754, recent: 11.129353233830846\n",
      "loss:  9221.756\n",
      "Episode: 211, steps: 8, reward: 8.0, average: 11.429245283018869, recent: 10.955223880597014\n",
      "Episode: 212, steps: 10, reward: 10.0, average: 11.422535211267606, recent: 10.925373134328359\n",
      "Episode: 213, steps: 10, reward: 10.0, average: 11.41588785046729, recent: 10.925373134328359\n",
      "Episode: 214, steps: 8, reward: 8.0, average: 11.4, recent: 10.900497512437811\n",
      "Episode: 215, steps: 9, reward: 9.0, average: 11.38888888888889, recent: 10.860696517412935\n",
      "Episode: 216, steps: 10, reward: 10.0, average: 11.382488479262673, recent: 10.845771144278608\n",
      "Episode: 217, steps: 9, reward: 9.0, average: 11.371559633027523, recent: 10.845771144278608\n",
      "Episode: 218, steps: 10, reward: 10.0, average: 11.365296803652969, recent: 10.82587064676617\n",
      "Episode: 219, steps: 8, reward: 8.0, average: 11.35, recent: 10.786069651741293\n",
      "Episode: 220, steps: 9, reward: 9.0, average: 11.339366515837105, recent: 10.676616915422885\n",
      "loss:  5.259264\n",
      "Episode: 221, steps: 11, reward: 11.0, average: 11.337837837837839, recent: 10.661691542288557\n",
      "Episode: 222, steps: 10, reward: 10.0, average: 11.331838565022421, recent: 10.661691542288557\n",
      "Episode: 223, steps: 10, reward: 10.0, average: 11.325892857142858, recent: 10.63681592039801\n",
      "Episode: 224, steps: 10, reward: 10.0, average: 11.32, recent: 10.626865671641792\n",
      "Episode: 225, steps: 9, reward: 9.0, average: 11.309734513274336, recent: 10.616915422885572\n",
      "Episode: 226, steps: 11, reward: 11.0, average: 11.308370044052863, recent: 10.616915422885572\n",
      "Episode: 227, steps: 11, reward: 11.0, average: 11.307017543859649, recent: 10.611940298507463\n",
      "Episode: 228, steps: 9, reward: 9.0, average: 11.296943231441048, recent: 10.592039800995025\n",
      "Episode: 229, steps: 10, reward: 10.0, average: 11.291304347826086, recent: 10.557213930348258\n",
      "Episode: 230, steps: 12, reward: 12.0, average: 11.294372294372295, recent: 10.552238805970148\n",
      "loss:  5.5438447\n",
      "Episode: 231, steps: 11, reward: 11.0, average: 11.293103448275861, recent: 10.562189054726367\n",
      "Episode: 232, steps: 10, reward: 10.0, average: 11.28755364806867, recent: 10.562189054726367\n",
      "Episode: 233, steps: 9, reward: 9.0, average: 11.277777777777779, recent: 10.567164179104477\n",
      "Episode: 234, steps: 11, reward: 11.0, average: 11.27659574468085, recent: 10.572139303482587\n",
      "Episode: 235, steps: 11, reward: 11.0, average: 11.275423728813559, recent: 10.577114427860696\n",
      "Episode: 236, steps: 8, reward: 8.0, average: 11.261603375527427, recent: 10.557213930348258\n",
      "Episode: 237, steps: 9, reward: 9.0, average: 11.252100840336135, recent: 10.527363184079602\n",
      "Episode: 238, steps: 12, reward: 12.0, average: 11.255230125523013, recent: 10.537313432835822\n",
      "Episode: 239, steps: 8, reward: 8.0, average: 11.241666666666667, recent: 10.512437810945274\n",
      "Episode: 240, steps: 11, reward: 11.0, average: 11.240663900414937, recent: 10.512437810945274\n",
      "loss:  18.828297\n",
      "Episode: 241, steps: 9, reward: 9.0, average: 11.231404958677686, recent: 10.497512437810945\n",
      "Episode: 242, steps: 13, reward: 13.0, average: 11.238683127572017, recent: 10.507462686567164\n",
      "Episode: 243, steps: 10, reward: 10.0, average: 11.23360655737705, recent: 10.497512437810945\n",
      "Episode: 244, steps: 10, reward: 10.0, average: 11.228571428571428, recent: 10.467661691542288\n",
      "Episode: 245, steps: 10, reward: 10.0, average: 11.223577235772357, recent: 10.472636815920398\n",
      "Episode: 246, steps: 10, reward: 10.0, average: 11.218623481781377, recent: 10.402985074626866\n",
      "Episode: 247, steps: 9, reward: 9.0, average: 11.209677419354838, recent: 10.398009950248756\n",
      "Episode: 248, steps: 10, reward: 10.0, average: 11.204819277108435, recent: 10.402985074626866\n",
      "Episode: 249, steps: 9, reward: 9.0, average: 11.196, recent: 10.35323383084577\n",
      "Episode: 250, steps: 10, reward: 10.0, average: 11.191235059760956, recent: 10.343283582089553\n",
      "loss:  7.428351\n",
      "Episode: 251, steps: 9, reward: 9.0, average: 11.182539682539682, recent: 10.333333333333334\n",
      "Episode: 252, steps: 9, reward: 9.0, average: 11.173913043478262, recent: 10.313432835820896\n",
      "Episode: 253, steps: 11, reward: 11.0, average: 11.173228346456693, recent: 10.313432835820896\n",
      "Episode: 254, steps: 11, reward: 11.0, average: 11.172549019607843, recent: 10.323383084577115\n",
      "Episode: 255, steps: 11, reward: 11.0, average: 11.171875, recent: 10.313432835820896\n",
      "Episode: 256, steps: 9, reward: 9.0, average: 11.163424124513618, recent: 10.288557213930348\n",
      "Episode: 257, steps: 9, reward: 9.0, average: 11.155038759689923, recent: 10.283582089552239\n",
      "Episode: 258, steps: 10, reward: 10.0, average: 11.150579150579151, recent: 10.283582089552239\n",
      "Episode: 259, steps: 9, reward: 9.0, average: 11.142307692307693, recent: 10.283582089552239\n",
      "Episode: 260, steps: 9, reward: 9.0, average: 11.134099616858238, recent: 10.278606965174129\n",
      "loss:  8283.557\n",
      "Episode: 261, steps: 10, reward: 10.0, average: 11.129770992366412, recent: 10.278606965174129\n",
      "Episode: 262, steps: 14, reward: 14.0, average: 11.140684410646388, recent: 10.243781094527364\n",
      "Episode: 263, steps: 9, reward: 9.0, average: 11.132575757575758, recent: 10.218905472636816\n",
      "Episode: 264, steps: 9, reward: 9.0, average: 11.124528301886793, recent: 10.203980099502488\n",
      "Episode: 265, steps: 9, reward: 9.0, average: 11.11654135338346, recent: 10.18407960199005\n",
      "Episode: 266, steps: 10, reward: 10.0, average: 11.112359550561798, recent: 10.17412935323383\n",
      "Episode: 267, steps: 10, reward: 10.0, average: 11.10820895522388, recent: 10.164179104477611\n",
      "Episode: 268, steps: 10, reward: 10.0, average: 11.104089219330856, recent: 10.159203980099502\n",
      "Episode: 269, steps: 9, reward: 9.0, average: 11.096296296296297, recent: 10.149253731343284\n",
      "Episode: 270, steps: 12, reward: 12.0, average: 11.099630996309964, recent: 10.154228855721392\n",
      "loss:  38.66232\n",
      "Episode: 271, steps: 10, reward: 10.0, average: 11.095588235294118, recent: 10.149253731343284\n",
      "Episode: 272, steps: 11, reward: 11.0, average: 11.095238095238095, recent: 10.154228855721392\n",
      "Episode: 273, steps: 10, reward: 10.0, average: 11.091240875912408, recent: 10.139303482587065\n",
      "Episode: 274, steps: 9, reward: 9.0, average: 11.083636363636364, recent: 10.119402985074627\n",
      "Episode: 275, steps: 10, reward: 10.0, average: 11.079710144927537, recent: 10.119402985074627\n",
      "Episode: 276, steps: 14, reward: 14.0, average: 11.090252707581227, recent: 10.149253731343284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 277, steps: 10, reward: 10.0, average: 11.086330935251798, recent: 10.149253731343284\n",
      "Episode: 278, steps: 9, reward: 9.0, average: 11.078853046594983, recent: 10.149253731343284\n",
      "Episode: 279, steps: 10, reward: 10.0, average: 11.075, recent: 10.149253731343284\n",
      "Episode: 280, steps: 10, reward: 10.0, average: 11.0711743772242, recent: 10.149253731343284\n",
      "loss:  92.68451\n",
      "Episode: 281, steps: 9, reward: 9.0, average: 11.063829787234043, recent: 10.129353233830846\n",
      "Episode: 282, steps: 9, reward: 9.0, average: 11.056537102473499, recent: 10.119402985074627\n",
      "Episode: 283, steps: 10, reward: 10.0, average: 11.05281690140845, recent: 10.109452736318408\n",
      "Episode: 284, steps: 9, reward: 9.0, average: 11.04561403508772, recent: 10.109452736318408\n",
      "Episode: 285, steps: 12, reward: 12.0, average: 11.048951048951048, recent: 10.074626865671641\n",
      "Episode: 286, steps: 10, reward: 10.0, average: 11.045296167247386, recent: 10.074626865671641\n",
      "Episode: 287, steps: 10, reward: 10.0, average: 11.041666666666666, recent: 10.069651741293532\n",
      "Episode: 288, steps: 9, reward: 9.0, average: 11.034602076124568, recent: 10.029850746268657\n",
      "Episode: 289, steps: 12, reward: 12.0, average: 11.037931034482758, recent: 10.039800995024876\n",
      "Episode: 290, steps: 9, reward: 9.0, average: 11.030927835051546, recent: 10.034825870646767\n",
      "loss:  17.03545\n",
      "Episode: 291, steps: 8, reward: 8.0, average: 11.020547945205479, recent: 10.029850746268657\n",
      "Episode: 292, steps: 10, reward: 10.0, average: 11.017064846416382, recent: 10.039800995024876\n",
      "Episode: 293, steps: 10, reward: 10.0, average: 11.013605442176871, recent: 10.044776119402986\n",
      "Episode: 294, steps: 11, reward: 11.0, average: 11.013559322033899, recent: 10.039800995024876\n",
      "Episode: 295, steps: 10, reward: 10.0, average: 11.010135135135135, recent: 10.049751243781095\n",
      "Episode: 296, steps: 10, reward: 10.0, average: 11.006734006734007, recent: 10.034825870646767\n",
      "Episode: 297, steps: 10, reward: 10.0, average: 11.003355704697986, recent: 10.019900497512438\n",
      "Episode: 298, steps: 13, reward: 13.0, average: 11.010033444816054, recent: 10.034825870646767\n",
      "Episode: 299, steps: 10, reward: 10.0, average: 11.006666666666666, recent: 10.024875621890548\n",
      "Episode: 300, steps: 9, reward: 9.0, average: 11.0, recent: 10.019900497512438\n",
      "loss:  3.5164888\n",
      "Episode: 301, steps: 9, reward: 9.0, average: 10.993377483443709, recent: 10.009950248756219\n",
      "Episode: 302, steps: 9, reward: 9.0, average: 10.986798679867986, recent: 10.014925373134329\n",
      "Episode: 303, steps: 9, reward: 9.0, average: 10.980263157894736, recent: 10.014925373134329\n",
      "Episode: 304, steps: 8, reward: 8.0, average: 10.970491803278689, recent: 10.009950248756219\n",
      "Episode: 305, steps: 9, reward: 9.0, average: 10.9640522875817, recent: 10.0\n",
      "Episode: 306, steps: 9, reward: 9.0, average: 10.957654723127035, recent: 10.0\n",
      "Episode: 307, steps: 9, reward: 9.0, average: 10.9512987012987, recent: 9.985074626865671\n",
      "Episode: 308, steps: 9, reward: 9.0, average: 10.944983818770227, recent: 9.980099502487562\n",
      "Episode: 309, steps: 8, reward: 8.0, average: 10.935483870967742, recent: 9.975124378109452\n",
      "Episode: 310, steps: 10, reward: 10.0, average: 10.932475884244372, recent: 9.970149253731343\n",
      "loss:  34.811943\n",
      "Episode: 311, steps: 10, reward: 10.0, average: 10.929487179487179, recent: 9.965174129353233\n",
      "Episode: 312, steps: 9, reward: 9.0, average: 10.92332268370607, recent: 9.960199004975124\n",
      "Episode: 313, steps: 9, reward: 9.0, average: 10.9171974522293, recent: 9.960199004975124\n",
      "Episode: 314, steps: 10, reward: 10.0, average: 10.914285714285715, recent: 9.965174129353233\n",
      "Episode: 315, steps: 10, reward: 10.0, average: 10.91139240506329, recent: 9.955223880597014\n",
      "Episode: 316, steps: 10, reward: 10.0, average: 10.908517350157728, recent: 9.950248756218905\n",
      "Episode: 317, steps: 10, reward: 10.0, average: 10.90566037735849, recent: 9.950248756218905\n",
      "Episode: 318, steps: 10, reward: 10.0, average: 10.90282131661442, recent: 9.960199004975124\n",
      "Episode: 319, steps: 9, reward: 9.0, average: 10.896875, recent: 9.955223880597014\n",
      "Episode: 320, steps: 9, reward: 9.0, average: 10.890965732087228, recent: 9.950248756218905\n",
      "loss:  110.47406\n",
      "Episode: 321, steps: 9, reward: 9.0, average: 10.885093167701863, recent: 9.945273631840797\n",
      "Episode: 322, steps: 10, reward: 10.0, average: 10.882352941176471, recent: 9.945273631840797\n",
      "Episode: 323, steps: 10, reward: 10.0, average: 10.87962962962963, recent: 9.945273631840797\n",
      "Episode: 324, steps: 10, reward: 10.0, average: 10.876923076923077, recent: 9.940298507462687\n",
      "Episode: 325, steps: 9, reward: 9.0, average: 10.871165644171779, recent: 9.935323383084578\n",
      "Episode: 326, steps: 9, reward: 9.0, average: 10.865443425076453, recent: 9.940298507462687\n",
      "Episode: 327, steps: 9, reward: 9.0, average: 10.859756097560975, recent: 9.940298507462687\n",
      "Episode: 328, steps: 8, reward: 8.0, average: 10.851063829787234, recent: 9.930348258706468\n",
      "Episode: 329, steps: 9, reward: 9.0, average: 10.845454545454546, recent: 9.935323383084578\n",
      "Episode: 330, steps: 10, reward: 10.0, average: 10.842900302114804, recent: 9.940298507462687\n",
      "loss:  5817.1626\n",
      "Episode: 331, steps: 10, reward: 10.0, average: 10.840361445783133, recent: 9.945273631840797\n",
      "Episode: 332, steps: 8, reward: 8.0, average: 10.831831831831831, recent: 9.940298507462687\n",
      "Episode: 333, steps: 8, reward: 8.0, average: 10.823353293413174, recent: 9.940298507462687\n",
      "Episode: 334, steps: 9, reward: 9.0, average: 10.817910447761195, recent: 9.935323383084578\n",
      "Episode: 335, steps: 10, reward: 10.0, average: 10.81547619047619, recent: 9.930348258706468\n",
      "Episode: 336, steps: 10, reward: 10.0, average: 10.813056379821958, recent: 9.935323383084578\n",
      "Episode: 337, steps: 11, reward: 11.0, average: 10.81360946745562, recent: 9.945273631840797\n",
      "Episode: 338, steps: 10, reward: 10.0, average: 10.811209439528023, recent: 9.945273631840797\n",
      "Episode: 339, steps: 11, reward: 11.0, average: 10.811764705882354, recent: 9.960199004975124\n",
      "Episode: 340, steps: 10, reward: 10.0, average: 10.809384164222873, recent: 9.945273631840797\n",
      "loss:  30.593102\n",
      "Episode: 341, steps: 10, reward: 10.0, average: 10.807017543859649, recent: 9.950248756218905\n",
      "Episode: 342, steps: 8, reward: 8.0, average: 10.798833819241983, recent: 9.92039800995025\n",
      "Episode: 343, steps: 12, reward: 12.0, average: 10.80232558139535, recent: 9.930348258706468\n",
      "Episode: 344, steps: 10, reward: 10.0, average: 10.8, recent: 9.92039800995025\n",
      "Episode: 345, steps: 10, reward: 10.0, average: 10.797687861271676, recent: 9.92039800995025\n",
      "Episode: 346, steps: 10, reward: 10.0, average: 10.795389048991355, recent: 9.925373134328359\n",
      "Episode: 347, steps: 10, reward: 10.0, average: 10.793103448275861, recent: 9.935323383084578\n",
      "Episode: 348, steps: 9, reward: 9.0, average: 10.787965616045845, recent: 9.930348258706468\n",
      "Episode: 349, steps: 11, reward: 11.0, average: 10.788571428571428, recent: 9.940298507462687\n",
      "Episode: 350, steps: 10, reward: 10.0, average: 10.786324786324787, recent: 9.935323383084578\n",
      "loss:  5402.844\n",
      "Episode: 351, steps: 11, reward: 11.0, average: 10.786931818181818, recent: 9.935323383084578\n",
      "Episode: 352, steps: 9, reward: 9.0, average: 10.78186968838527, recent: 9.930348258706468\n",
      "Episode: 353, steps: 12, reward: 12.0, average: 10.785310734463277, recent: 9.930348258706468\n",
      "Episode: 354, steps: 9, reward: 9.0, average: 10.780281690140844, recent: 9.930348258706468\n",
      "Episode: 355, steps: 8, reward: 8.0, average: 10.77247191011236, recent: 9.925373134328359\n",
      "Episode: 356, steps: 9, reward: 9.0, average: 10.767507002801121, recent: 9.92039800995025\n",
      "Episode: 357, steps: 10, reward: 10.0, average: 10.76536312849162, recent: 9.925373134328359\n",
      "Episode: 358, steps: 10, reward: 10.0, average: 10.763231197771587, recent: 9.930348258706468\n",
      "Episode: 359, steps: 10, reward: 10.0, average: 10.761111111111111, recent: 9.935323383084578\n",
      "Episode: 360, steps: 8, reward: 8.0, average: 10.753462603878116, recent: 9.925373134328359\n",
      "loss:  3.6529548\n",
      "Episode: 361, steps: 9, reward: 9.0, average: 10.748618784530386, recent: 9.925373134328359\n",
      "Episode: 362, steps: 10, reward: 10.0, average: 10.746556473829202, recent: 9.930348258706468\n",
      "Episode: 363, steps: 9, reward: 9.0, average: 10.741758241758241, recent: 9.925373134328359\n",
      "Episode: 364, steps: 9, reward: 9.0, average: 10.736986301369862, recent: 9.925373134328359\n",
      "Episode: 365, steps: 9, reward: 9.0, average: 10.73224043715847, recent: 9.92039800995025\n",
      "Episode: 366, steps: 9, reward: 9.0, average: 10.727520435967303, recent: 9.91542288557214\n",
      "Episode: 367, steps: 11, reward: 11.0, average: 10.728260869565217, recent: 9.925373134328359\n",
      "Episode: 368, steps: 9, reward: 9.0, average: 10.723577235772357, recent: 9.91542288557214\n",
      "Episode: 369, steps: 10, reward: 10.0, average: 10.721621621621622, recent: 9.91542288557214\n",
      "Episode: 370, steps: 10, reward: 10.0, average: 10.719676549865229, recent: 9.90547263681592\n",
      "loss:  4291.971\n",
      "Episode: 371, steps: 12, reward: 12.0, average: 10.723118279569892, recent: 9.92039800995025\n",
      "Episode: 372, steps: 10, reward: 10.0, average: 10.72117962466488, recent: 9.92039800995025\n",
      "Episode: 373, steps: 9, reward: 9.0, average: 10.716577540106952, recent: 9.90547263681592\n",
      "Episode: 374, steps: 9, reward: 9.0, average: 10.712, recent: 9.900497512437811\n",
      "Episode: 375, steps: 10, reward: 10.0, average: 10.710106382978724, recent: 9.890547263681592\n",
      "Episode: 376, steps: 8, reward: 8.0, average: 10.702917771883289, recent: 9.860696517412935\n",
      "Episode: 377, steps: 11, reward: 11.0, average: 10.703703703703704, recent: 9.860696517412935\n",
      "Episode: 378, steps: 12, reward: 12.0, average: 10.70712401055409, recent: 9.870646766169154\n",
      "Episode: 379, steps: 8, reward: 8.0, average: 10.7, recent: 9.860696517412935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 380, steps: 10, reward: 10.0, average: 10.698162729658792, recent: 9.855721393034825\n",
      "loss:  612.87305\n",
      "Episode: 381, steps: 9, reward: 9.0, average: 10.693717277486911, recent: 9.845771144278608\n",
      "Episode: 382, steps: 10, reward: 10.0, average: 10.691906005221933, recent: 9.845771144278608\n",
      "Episode: 383, steps: 8, reward: 8.0, average: 10.684895833333334, recent: 9.83084577114428\n",
      "Episode: 384, steps: 9, reward: 9.0, average: 10.68051948051948, recent: 9.82587064676617\n",
      "Episode: 385, steps: 10, reward: 10.0, average: 10.678756476683938, recent: 9.82587064676617\n",
      "Episode: 386, steps: 10, reward: 10.0, average: 10.677002583979329, recent: 9.83084577114428\n",
      "Episode: 387, steps: 9, reward: 9.0, average: 10.672680412371134, recent: 9.835820895522389\n",
      "Episode: 388, steps: 10, reward: 10.0, average: 10.67095115681234, recent: 9.845771144278608\n",
      "Episode: 389, steps: 10, reward: 10.0, average: 10.669230769230769, recent: 9.845771144278608\n",
      "Episode: 390, steps: 9, reward: 9.0, average: 10.664961636828645, recent: 9.835820895522389\n",
      "loss:  290.25296\n",
      "Episode: 391, steps: 8, reward: 8.0, average: 10.658163265306122, recent: 9.82587064676617\n",
      "Episode: 392, steps: 10, reward: 10.0, average: 10.65648854961832, recent: 9.82587064676617\n",
      "Episode: 393, steps: 8, reward: 8.0, average: 10.649746192893401, recent: 9.81592039800995\n",
      "Episode: 394, steps: 11, reward: 11.0, average: 10.650632911392405, recent: 9.82089552238806\n",
      "Episode: 395, steps: 9, reward: 9.0, average: 10.646464646464647, recent: 9.800995024875622\n",
      "Episode: 396, steps: 10, reward: 10.0, average: 10.644836272040303, recent: 9.791044776119403\n",
      "Episode: 397, steps: 10, reward: 10.0, average: 10.64321608040201, recent: 9.796019900497512\n",
      "Episode: 398, steps: 10, reward: 10.0, average: 10.641604010025063, recent: 9.796019900497512\n",
      "Episode: 399, steps: 9, reward: 9.0, average: 10.6375, recent: 9.791044776119403\n",
      "Episode: 400, steps: 8, reward: 8.0, average: 10.630922693266832, recent: 9.786069651741293\n",
      "loss:  597.8395\n",
      "Episode: 401, steps: 10, reward: 10.0, average: 10.629353233830846, recent: 9.786069651741293\n",
      "Episode: 402, steps: 9, reward: 9.0, average: 10.62531017369727, recent: 9.746268656716419\n",
      "Episode: 403, steps: 9, reward: 9.0, average: 10.621287128712872, recent: 9.7363184079602\n",
      "Episode: 404, steps: 10, reward: 10.0, average: 10.619753086419752, recent: 9.73134328358209\n",
      "Episode: 405, steps: 10, reward: 10.0, average: 10.618226600985222, recent: 9.7363184079602\n",
      "Episode: 406, steps: 10, reward: 10.0, average: 10.616707616707616, recent: 9.74129353233831\n",
      "Episode: 407, steps: 9, reward: 9.0, average: 10.612745098039216, recent: 9.7363184079602\n",
      "Episode: 408, steps: 8, reward: 8.0, average: 10.60635696821516, recent: 9.73134328358209\n",
      "Episode: 409, steps: 9, reward: 9.0, average: 10.602439024390243, recent: 9.706467661691542\n",
      "Episode: 410, steps: 10, reward: 10.0, average: 10.600973236009732, recent: 9.716417910447761\n",
      "loss:  630.9568\n",
      "Episode: 411, steps: 11, reward: 11.0, average: 10.601941747572816, recent: 9.716417910447761\n",
      "Episode: 412, steps: 10, reward: 10.0, average: 10.60048426150121, recent: 9.72636815920398\n",
      "Episode: 413, steps: 12, reward: 12.0, average: 10.603864734299517, recent: 9.7363184079602\n",
      "Episode: 414, steps: 11, reward: 11.0, average: 10.604819277108433, recent: 9.74129353233831\n",
      "Episode: 415, steps: 9, reward: 9.0, average: 10.600961538461538, recent: 9.746268656716419\n",
      "Episode: 416, steps: 10, reward: 10.0, average: 10.599520383693045, recent: 9.751243781094526\n",
      "Episode: 417, steps: 9, reward: 9.0, average: 10.595693779904305, recent: 9.746268656716419\n",
      "Episode: 418, steps: 8, reward: 8.0, average: 10.589498806682577, recent: 9.74129353233831\n",
      "Episode: 419, steps: 12, reward: 12.0, average: 10.592857142857143, recent: 9.751243781094526\n",
      "Episode: 420, steps: 9, reward: 9.0, average: 10.589073634204276, recent: 9.756218905472636\n",
      "loss:  81.23268\n",
      "Episode: 421, steps: 9, reward: 9.0, average: 10.585308056872037, recent: 9.756218905472636\n",
      "Episode: 422, steps: 10, reward: 10.0, average: 10.583924349881796, recent: 9.751243781094526\n",
      "Episode: 423, steps: 9, reward: 9.0, average: 10.580188679245284, recent: 9.746268656716419\n",
      "Episode: 424, steps: 8, reward: 8.0, average: 10.574117647058824, recent: 9.7363184079602\n",
      "Episode: 425, steps: 9, reward: 9.0, average: 10.570422535211268, recent: 9.73134328358209\n",
      "Episode: 426, steps: 11, reward: 11.0, average: 10.571428571428571, recent: 9.74129353233831\n",
      "Episode: 427, steps: 10, reward: 10.0, average: 10.570093457943925, recent: 9.7363184079602\n",
      "Episode: 428, steps: 10, reward: 10.0, average: 10.56876456876457, recent: 9.73134328358209\n",
      "Episode: 429, steps: 8, reward: 8.0, average: 10.56279069767442, recent: 9.72636815920398\n",
      "Episode: 430, steps: 9, reward: 9.0, average: 10.559164733178655, recent: 9.721393034825871\n",
      "loss:  0.00018022723\n",
      "Episode: 431, steps: 9, reward: 9.0, average: 10.555555555555555, recent: 9.706467661691542\n",
      "Episode: 432, steps: 9, reward: 9.0, average: 10.551963048498845, recent: 9.696517412935323\n",
      "Episode: 433, steps: 11, reward: 11.0, average: 10.55299539170507, recent: 9.701492537313433\n",
      "Episode: 434, steps: 10, reward: 10.0, average: 10.551724137931034, recent: 9.706467661691542\n",
      "Episode: 435, steps: 8, reward: 8.0, average: 10.545871559633028, recent: 9.691542288557214\n",
      "Episode: 436, steps: 11, reward: 11.0, average: 10.546910755148742, recent: 9.691542288557214\n",
      "Episode: 437, steps: 11, reward: 11.0, average: 10.547945205479452, recent: 9.706467661691542\n",
      "Episode: 438, steps: 8, reward: 8.0, average: 10.542141230068337, recent: 9.701492537313433\n",
      "Episode: 439, steps: 10, reward: 10.0, average: 10.540909090909091, recent: 9.691542288557214\n",
      "Episode: 440, steps: 9, reward: 9.0, average: 10.537414965986395, recent: 9.696517412935323\n",
      "loss:  3381.6697\n",
      "Episode: 441, steps: 10, reward: 10.0, average: 10.536199095022624, recent: 9.691542288557214\n",
      "Episode: 442, steps: 9, reward: 9.0, average: 10.53273137697517, recent: 9.691542288557214\n",
      "Episode: 443, steps: 11, reward: 11.0, average: 10.533783783783784, recent: 9.681592039800995\n",
      "Episode: 444, steps: 10, reward: 10.0, average: 10.532584269662921, recent: 9.681592039800995\n",
      "Episode: 445, steps: 9, reward: 9.0, average: 10.52914798206278, recent: 9.676616915422885\n",
      "Episode: 446, steps: 9, reward: 9.0, average: 10.52572706935123, recent: 9.671641791044776\n",
      "Episode: 447, steps: 10, reward: 10.0, average: 10.524553571428571, recent: 9.671641791044776\n",
      "Episode: 448, steps: 9, reward: 9.0, average: 10.521158129175946, recent: 9.671641791044776\n",
      "Episode: 449, steps: 8, reward: 8.0, average: 10.515555555555556, recent: 9.661691542288557\n",
      "Episode: 450, steps: 9, reward: 9.0, average: 10.512195121951219, recent: 9.661691542288557\n",
      "loss:  66.40715\n",
      "Episode: 451, steps: 10, reward: 10.0, average: 10.511061946902656, recent: 9.661691542288557\n",
      "Episode: 452, steps: 9, reward: 9.0, average: 10.507726269315674, recent: 9.661691542288557\n",
      "Episode: 453, steps: 9, reward: 9.0, average: 10.504405286343612, recent: 9.661691542288557\n",
      "Episode: 454, steps: 11, reward: 11.0, average: 10.505494505494505, recent: 9.661691542288557\n",
      "Episode: 455, steps: 10, reward: 10.0, average: 10.50438596491228, recent: 9.656716417910447\n",
      "Episode: 456, steps: 11, reward: 11.0, average: 10.5054704595186, recent: 9.656716417910447\n",
      "Episode: 457, steps: 10, reward: 10.0, average: 10.504366812227074, recent: 9.661691542288557\n",
      "Episode: 458, steps: 10, reward: 10.0, average: 10.50326797385621, recent: 9.666666666666666\n",
      "Episode: 459, steps: 9, reward: 9.0, average: 10.5, recent: 9.661691542288557\n",
      "Episode: 460, steps: 11, reward: 11.0, average: 10.501084598698482, recent: 9.671641791044776\n",
      "loss:  78.390816\n",
      "Episode: 461, steps: 9, reward: 9.0, average: 10.497835497835498, recent: 9.671641791044776\n",
      "Episode: 462, steps: 9, reward: 9.0, average: 10.494600431965443, recent: 9.666666666666666\n",
      "Episode: 463, steps: 9, reward: 9.0, average: 10.491379310344827, recent: 9.64179104477612\n",
      "Episode: 464, steps: 10, reward: 10.0, average: 10.490322580645161, recent: 9.64676616915423\n",
      "Episode: 465, steps: 11, reward: 11.0, average: 10.491416309012875, recent: 9.656716417910447\n",
      "Episode: 466, steps: 9, reward: 9.0, average: 10.488222698072805, recent: 9.656716417910447\n",
      "Episode: 467, steps: 10, reward: 10.0, average: 10.487179487179487, recent: 9.656716417910447\n",
      "Episode: 468, steps: 10, reward: 10.0, average: 10.486140724946695, recent: 9.656716417910447\n",
      "Episode: 469, steps: 9, reward: 9.0, average: 10.482978723404255, recent: 9.651741293532337\n",
      "Episode: 470, steps: 10, reward: 10.0, average: 10.481953290870488, recent: 9.656716417910447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  9.123038\n",
      "Episode: 471, steps: 9, reward: 9.0, average: 10.478813559322035, recent: 9.64179104477612\n",
      "Episode: 472, steps: 9, reward: 9.0, average: 10.47568710359408, recent: 9.63681592039801\n",
      "Episode: 473, steps: 11, reward: 11.0, average: 10.476793248945148, recent: 9.63681592039801\n",
      "Episode: 474, steps: 10, reward: 10.0, average: 10.47578947368421, recent: 9.63681592039801\n",
      "Episode: 475, steps: 10, reward: 10.0, average: 10.474789915966387, recent: 9.64179104477612\n",
      "Episode: 476, steps: 9, reward: 9.0, average: 10.471698113207546, recent: 9.63681592039801\n",
      "Episode: 477, steps: 10, reward: 10.0, average: 10.47071129707113, recent: 9.616915422885572\n",
      "Episode: 478, steps: 10, reward: 10.0, average: 10.46972860125261, recent: 9.616915422885572\n",
      "Episode: 479, steps: 8, reward: 8.0, average: 10.464583333333334, recent: 9.611940298507463\n",
      "Episode: 480, steps: 11, reward: 11.0, average: 10.465696465696466, recent: 9.616915422885572\n",
      "loss:  148.69687\n",
      "Episode: 481, steps: 9, reward: 9.0, average: 10.462655601659751, recent: 9.611940298507463\n",
      "Episode: 482, steps: 11, reward: 11.0, average: 10.46376811594203, recent: 9.621890547263682\n",
      "Episode: 483, steps: 10, reward: 10.0, average: 10.462809917355372, recent: 9.626865671641792\n",
      "Episode: 484, steps: 9, reward: 9.0, average: 10.45979381443299, recent: 9.621890547263682\n",
      "Episode: 485, steps: 10, reward: 10.0, average: 10.458847736625515, recent: 9.626865671641792\n",
      "Episode: 486, steps: 9, reward: 9.0, average: 10.455852156057494, recent: 9.611940298507463\n",
      "Episode: 487, steps: 9, reward: 9.0, average: 10.452868852459016, recent: 9.606965174129353\n",
      "Episode: 488, steps: 10, reward: 10.0, average: 10.451942740286299, recent: 9.606965174129353\n",
      "Episode: 489, steps: 10, reward: 10.0, average: 10.451020408163265, recent: 9.611940298507463\n",
      "Episode: 490, steps: 10, reward: 10.0, average: 10.45010183299389, recent: 9.601990049751244\n",
      "loss:  272.75156\n",
      "Episode: 491, steps: 9, reward: 9.0, average: 10.447154471544716, recent: 9.601990049751244\n",
      "Episode: 492, steps: 8, reward: 8.0, average: 10.442190669371197, recent: 9.601990049751244\n",
      "Episode: 493, steps: 11, reward: 11.0, average: 10.44331983805668, recent: 9.606965174129353\n",
      "Episode: 494, steps: 9, reward: 9.0, average: 10.44040404040404, recent: 9.601990049751244\n",
      "Episode: 495, steps: 9, reward: 9.0, average: 10.4375, recent: 9.592039800995025\n",
      "Episode: 496, steps: 9, reward: 9.0, average: 10.434607645875252, recent: 9.587064676616915\n",
      "Episode: 497, steps: 8, reward: 8.0, average: 10.429718875502008, recent: 9.577114427860696\n",
      "Episode: 498, steps: 9, reward: 9.0, average: 10.42685370741483, recent: 9.572139303482587\n",
      "Episode: 499, steps: 10, reward: 10.0, average: 10.426, recent: 9.557213930348258\n",
      "Episode: 500, steps: 10, reward: 10.0, average: 10.425149700598803, recent: 9.557213930348258\n",
      "loss:  389.71323\n",
      "Episode: 501, steps: 10, reward: 10.0, average: 10.42430278884462, recent: 9.562189054726367\n",
      "Episode: 502, steps: 9, reward: 9.0, average: 10.421471172962226, recent: 9.562189054726367\n",
      "Episode: 503, steps: 9, reward: 9.0, average: 10.418650793650794, recent: 9.562189054726367\n",
      "Episode: 504, steps: 10, reward: 10.0, average: 10.417821782178217, recent: 9.567164179104477\n",
      "Episode: 505, steps: 11, reward: 11.0, average: 10.41897233201581, recent: 9.582089552238806\n",
      "Episode: 506, steps: 8, reward: 8.0, average: 10.414201183431953, recent: 9.577114427860696\n",
      "Episode: 507, steps: 10, reward: 10.0, average: 10.413385826771654, recent: 9.582089552238806\n",
      "Episode: 508, steps: 10, reward: 10.0, average: 10.412573673870334, recent: 9.587064676616915\n",
      "Episode: 509, steps: 9, reward: 9.0, average: 10.409803921568628, recent: 9.587064676616915\n",
      "Episode: 510, steps: 8, reward: 8.0, average: 10.405088062622308, recent: 9.587064676616915\n",
      "loss:  55.27424\n",
      "Episode: 511, steps: 10, reward: 10.0, average: 10.404296875, recent: 9.587064676616915\n",
      "Episode: 512, steps: 10, reward: 10.0, average: 10.403508771929825, recent: 9.587064676616915\n",
      "Episode: 513, steps: 9, reward: 9.0, average: 10.400778210116732, recent: 9.587064676616915\n",
      "Episode: 514, steps: 12, reward: 12.0, average: 10.403883495145632, recent: 9.601990049751244\n",
      "Episode: 515, steps: 10, reward: 10.0, average: 10.4031007751938, recent: 9.601990049751244\n",
      "Episode: 516, steps: 10, reward: 10.0, average: 10.402321083172147, recent: 9.601990049751244\n",
      "Episode: 517, steps: 9, reward: 9.0, average: 10.3996138996139, recent: 9.597014925373134\n",
      "Episode: 518, steps: 10, reward: 10.0, average: 10.398843930635838, recent: 9.597014925373134\n",
      "Episode: 519, steps: 9, reward: 9.0, average: 10.396153846153846, recent: 9.592039800995025\n",
      "Episode: 520, steps: 13, reward: 13.0, average: 10.401151631477926, recent: 9.611940298507463\n",
      "loss:  697.5387\n",
      "Episode: 521, steps: 10, reward: 10.0, average: 10.400383141762452, recent: 9.616915422885572\n",
      "Episode: 522, steps: 9, reward: 9.0, average: 10.397705544933078, recent: 9.616915422885572\n",
      "Episode: 523, steps: 8, reward: 8.0, average: 10.393129770992367, recent: 9.606965174129353\n",
      "Episode: 524, steps: 9, reward: 9.0, average: 10.39047619047619, recent: 9.601990049751244\n",
      "Episode: 525, steps: 9, reward: 9.0, average: 10.387832699619771, recent: 9.597014925373134\n",
      "Episode: 526, steps: 9, reward: 9.0, average: 10.385199240986717, recent: 9.597014925373134\n",
      "Episode: 527, steps: 9, reward: 9.0, average: 10.382575757575758, recent: 9.597014925373134\n",
      "Episode: 528, steps: 10, reward: 10.0, average: 10.381852551984878, recent: 9.601990049751244\n",
      "Episode: 529, steps: 10, reward: 10.0, average: 10.381132075471697, recent: 9.611940298507463\n",
      "Episode: 530, steps: 9, reward: 9.0, average: 10.378531073446327, recent: 9.611940298507463\n",
      "loss:  17.527996\n",
      "Episode: 531, steps: 8, reward: 8.0, average: 10.37406015037594, recent: 9.601990049751244\n",
      "Episode: 532, steps: 9, reward: 9.0, average: 10.371482176360225, recent: 9.597014925373134\n",
      "Episode: 533, steps: 10, reward: 10.0, average: 10.370786516853933, recent: 9.606965174129353\n",
      "Episode: 534, steps: 9, reward: 9.0, average: 10.368224299065421, recent: 9.611940298507463\n",
      "Episode: 535, steps: 10, reward: 10.0, average: 10.367537313432836, recent: 9.616915422885572\n",
      "Episode: 536, steps: 8, reward: 8.0, average: 10.363128491620111, recent: 9.606965174129353\n",
      "Episode: 537, steps: 9, reward: 9.0, average: 10.360594795539033, recent: 9.601990049751244\n",
      "Episode: 538, steps: 9, reward: 9.0, average: 10.358070500927644, recent: 9.592039800995025\n",
      "Episode: 539, steps: 10, reward: 10.0, average: 10.357407407407408, recent: 9.592039800995025\n",
      "Episode: 540, steps: 10, reward: 10.0, average: 10.356746765249538, recent: 9.587064676616915\n",
      "loss:  555.0976\n",
      "Episode: 541, steps: 9, reward: 9.0, average: 10.354243542435425, recent: 9.582089552238806\n",
      "Episode: 542, steps: 10, reward: 10.0, average: 10.353591160220995, recent: 9.582089552238806\n",
      "Episode: 543, steps: 10, reward: 10.0, average: 10.352941176470589, recent: 9.592039800995025\n",
      "Episode: 544, steps: 9, reward: 9.0, average: 10.35045871559633, recent: 9.577114427860696\n",
      "Episode: 545, steps: 11, reward: 11.0, average: 10.351648351648352, recent: 9.582089552238806\n",
      "Episode: 546, steps: 10, reward: 10.0, average: 10.351005484460694, recent: 9.582089552238806\n",
      "Episode: 547, steps: 11, reward: 11.0, average: 10.352189781021897, recent: 9.587064676616915\n",
      "Episode: 548, steps: 10, reward: 10.0, average: 10.351548269581057, recent: 9.587064676616915\n",
      "Episode: 549, steps: 10, reward: 10.0, average: 10.350909090909092, recent: 9.592039800995025\n",
      "Episode: 550, steps: 10, reward: 10.0, average: 10.350272232304901, recent: 9.587064676616915\n",
      "loss:  257.21817\n",
      "Episode: 551, steps: 10, reward: 10.0, average: 10.34963768115942, recent: 9.587064676616915\n",
      "Episode: 552, steps: 8, reward: 8.0, average: 10.345388788426764, recent: 9.572139303482587\n",
      "Episode: 553, steps: 10, reward: 10.0, average: 10.344765342960288, recent: 9.577114427860696\n",
      "Episode: 554, steps: 11, reward: 11.0, average: 10.345945945945946, recent: 9.572139303482587\n",
      "Episode: 555, steps: 9, reward: 9.0, average: 10.343525179856115, recent: 9.572139303482587\n",
      "Episode: 556, steps: 8, reward: 8.0, average: 10.339317773788151, recent: 9.572139303482587\n",
      "Episode: 557, steps: 9, reward: 9.0, average: 10.336917562724015, recent: 9.572139303482587\n",
      "Episode: 558, steps: 8, reward: 8.0, average: 10.33273703041145, recent: 9.562189054726367\n",
      "Episode: 559, steps: 9, reward: 9.0, average: 10.330357142857142, recent: 9.557213930348258\n",
      "Episode: 560, steps: 9, reward: 9.0, average: 10.327985739750446, recent: 9.552238805970148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.35267752\n",
      "Episode: 561, steps: 9, reward: 9.0, average: 10.325622775800712, recent: 9.557213930348258\n",
      "Episode: 562, steps: 11, reward: 11.0, average: 10.326820603907638, recent: 9.567164179104477\n",
      "Episode: 563, steps: 10, reward: 10.0, average: 10.326241134751774, recent: 9.567164179104477\n",
      "Episode: 564, steps: 10, reward: 10.0, average: 10.325663716814159, recent: 9.572139303482587\n",
      "Episode: 565, steps: 9, reward: 9.0, average: 10.323321554770319, recent: 9.572139303482587\n",
      "Episode: 566, steps: 9, reward: 9.0, average: 10.320987654320987, recent: 9.572139303482587\n",
      "Episode: 567, steps: 8, reward: 8.0, average: 10.316901408450704, recent: 9.567164179104477\n",
      "Episode: 568, steps: 11, reward: 11.0, average: 10.318101933216168, recent: 9.567164179104477\n",
      "Episode: 569, steps: 10, reward: 10.0, average: 10.317543859649122, recent: 9.572139303482587\n",
      "Episode: 570, steps: 8, reward: 8.0, average: 10.313485113835377, recent: 9.562189054726367\n",
      "loss:  3212.0383\n",
      "Episode: 571, steps: 9, reward: 9.0, average: 10.311188811188812, recent: 9.557213930348258\n",
      "Episode: 572, steps: 10, reward: 10.0, average: 10.31064572425829, recent: 9.54726368159204\n",
      "Episode: 573, steps: 11, reward: 11.0, average: 10.31184668989547, recent: 9.552238805970148\n",
      "Episode: 574, steps: 9, reward: 9.0, average: 10.309565217391304, recent: 9.552238805970148\n",
      "Episode: 575, steps: 10, reward: 10.0, average: 10.309027777777779, recent: 9.557213930348258\n",
      "Episode: 576, steps: 9, reward: 9.0, average: 10.306759098786829, recent: 9.552238805970148\n",
      "Episode: 577, steps: 11, reward: 11.0, average: 10.30795847750865, recent: 9.567164179104477\n",
      "Episode: 578, steps: 10, reward: 10.0, average: 10.307426597582038, recent: 9.562189054726367\n",
      "Episode: 579, steps: 10, reward: 10.0, average: 10.306896551724138, recent: 9.552238805970148\n",
      "Episode: 580, steps: 9, reward: 9.0, average: 10.304647160068846, recent: 9.557213930348258\n",
      "loss:  0.0019191186\n",
      "Episode: 581, steps: 9, reward: 9.0, average: 10.302405498281788, recent: 9.552238805970148\n",
      "Episode: 582, steps: 10, reward: 10.0, average: 10.30188679245283, recent: 9.557213930348258\n",
      "Episode: 583, steps: 10, reward: 10.0, average: 10.301369863013699, recent: 9.557213930348258\n",
      "Episode: 584, steps: 11, reward: 11.0, average: 10.302564102564103, recent: 9.572139303482587\n",
      "Episode: 585, steps: 8, reward: 8.0, average: 10.29863481228669, recent: 9.567164179104477\n",
      "Episode: 586, steps: 9, reward: 9.0, average: 10.296422487223168, recent: 9.562189054726367\n",
      "Episode: 587, steps: 11, reward: 11.0, average: 10.297619047619047, recent: 9.567164179104477\n",
      "Episode: 588, steps: 10, reward: 10.0, average: 10.297113752122241, recent: 9.572139303482587\n",
      "Episode: 589, steps: 8, reward: 8.0, average: 10.293220338983051, recent: 9.562189054726367\n",
      "Episode: 590, steps: 9, reward: 9.0, average: 10.29103214890017, recent: 9.557213930348258\n",
      "loss:  52.210262\n",
      "Episode: 591, steps: 10, reward: 10.0, average: 10.29054054054054, recent: 9.562189054726367\n",
      "Episode: 592, steps: 10, reward: 10.0, average: 10.290050590219224, recent: 9.572139303482587\n",
      "Episode: 593, steps: 9, reward: 9.0, average: 10.287878787878787, recent: 9.567164179104477\n",
      "Episode: 594, steps: 8, reward: 8.0, average: 10.284033613445379, recent: 9.567164179104477\n",
      "Episode: 595, steps: 10, reward: 10.0, average: 10.283557046979865, recent: 9.562189054726367\n",
      "Episode: 596, steps: 9, reward: 9.0, average: 10.28140703517588, recent: 9.562189054726367\n",
      "Episode: 597, steps: 9, reward: 9.0, average: 10.279264214046822, recent: 9.557213930348258\n",
      "Episode: 598, steps: 8, reward: 8.0, average: 10.275459098497496, recent: 9.54726368159204\n",
      "Episode: 599, steps: 10, reward: 10.0, average: 10.275, recent: 9.54726368159204\n",
      "Episode: 600, steps: 10, reward: 10.0, average: 10.274542429284526, recent: 9.552238805970148\n",
      "loss:  24.233788\n",
      "Episode: 601, steps: 9, reward: 9.0, average: 10.272425249169435, recent: 9.557213930348258\n",
      "Episode: 602, steps: 11, reward: 11.0, average: 10.27363184079602, recent: 9.562189054726367\n",
      "Episode: 603, steps: 10, reward: 10.0, average: 10.27317880794702, recent: 9.567164179104477\n",
      "Episode: 604, steps: 10, reward: 10.0, average: 10.272727272727273, recent: 9.572139303482587\n",
      "Episode: 605, steps: 11, reward: 11.0, average: 10.273927392739274, recent: 9.577114427860696\n",
      "Episode: 606, steps: 8, reward: 8.0, average: 10.270181219110379, recent: 9.567164179104477\n",
      "Episode: 607, steps: 8, reward: 8.0, average: 10.266447368421053, recent: 9.557213930348258\n",
      "Episode: 608, steps: 11, reward: 11.0, average: 10.267651888341543, recent: 9.567164179104477\n",
      "Episode: 609, steps: 11, reward: 11.0, average: 10.268852459016394, recent: 9.582089552238806\n",
      "Episode: 610, steps: 10, reward: 10.0, average: 10.268412438625205, recent: 9.587064676616915\n",
      "loss:  69.175\n",
      "Episode: 611, steps: 9, reward: 9.0, average: 10.266339869281046, recent: 9.582089552238806\n",
      "Episode: 612, steps: 8, reward: 8.0, average: 10.262642740619903, recent: 9.567164179104477\n",
      "Episode: 613, steps: 10, reward: 10.0, average: 10.262214983713354, recent: 9.567164179104477\n",
      "Episode: 614, steps: 10, reward: 10.0, average: 10.261788617886179, recent: 9.557213930348258\n",
      "Episode: 615, steps: 9, reward: 9.0, average: 10.25974025974026, recent: 9.54726368159204\n",
      "Episode: 616, steps: 9, reward: 9.0, average: 10.257698541329011, recent: 9.54726368159204\n",
      "Episode: 617, steps: 9, reward: 9.0, average: 10.255663430420713, recent: 9.542288557213931\n",
      "Episode: 618, steps: 12, reward: 12.0, average: 10.258481421647819, recent: 9.557213930348258\n",
      "Episode: 619, steps: 10, reward: 10.0, average: 10.258064516129032, recent: 9.567164179104477\n",
      "Episode: 620, steps: 9, reward: 9.0, average: 10.256038647342995, recent: 9.552238805970148\n",
      "loss:  1517.1908\n",
      "Episode: 621, steps: 12, reward: 12.0, average: 10.258842443729904, recent: 9.567164179104477\n",
      "Episode: 622, steps: 10, reward: 10.0, average: 10.258426966292134, recent: 9.572139303482587\n",
      "Episode: 623, steps: 8, reward: 8.0, average: 10.254807692307692, recent: 9.562189054726367\n",
      "Episode: 624, steps: 11, reward: 11.0, average: 10.256, recent: 9.572139303482587\n",
      "Episode: 625, steps: 10, reward: 10.0, average: 10.255591054313099, recent: 9.582089552238806\n",
      "Episode: 626, steps: 9, reward: 9.0, average: 10.253588516746412, recent: 9.582089552238806\n",
      "Episode: 627, steps: 10, reward: 10.0, average: 10.253184713375797, recent: 9.577114427860696\n",
      "Episode: 628, steps: 10, reward: 10.0, average: 10.252782193958664, recent: 9.577114427860696\n",
      "Episode: 629, steps: 9, reward: 9.0, average: 10.250793650793652, recent: 9.572139303482587\n",
      "Episode: 630, steps: 10, reward: 10.0, average: 10.25039619651347, recent: 9.582089552238806\n",
      "loss:  0.5234029\n",
      "Episode: 631, steps: 10, reward: 10.0, average: 10.25, recent: 9.587064676616915\n",
      "Episode: 632, steps: 10, reward: 10.0, average: 10.249605055292259, recent: 9.592039800995025\n",
      "Episode: 633, steps: 8, reward: 8.0, average: 10.246056782334385, recent: 9.587064676616915\n",
      "Episode: 634, steps: 10, reward: 10.0, average: 10.245669291338583, recent: 9.582089552238806\n",
      "Episode: 635, steps: 9, reward: 9.0, average: 10.2437106918239, recent: 9.577114427860696\n",
      "Episode: 636, steps: 11, reward: 11.0, average: 10.244897959183673, recent: 9.592039800995025\n",
      "Episode: 637, steps: 9, reward: 9.0, average: 10.24294670846395, recent: 9.582089552238806\n",
      "Episode: 638, steps: 10, reward: 10.0, average: 10.242566510172145, recent: 9.577114427860696\n",
      "Episode: 639, steps: 10, reward: 10.0, average: 10.2421875, recent: 9.587064676616915\n",
      "Episode: 640, steps: 10, reward: 10.0, average: 10.241809672386896, recent: 9.587064676616915\n",
      "loss:  285.17352\n",
      "Episode: 641, steps: 9, reward: 9.0, average: 10.2398753894081, recent: 9.587064676616915\n",
      "Episode: 642, steps: 11, reward: 11.0, average: 10.241057542768274, recent: 9.592039800995025\n",
      "Episode: 643, steps: 8, reward: 8.0, average: 10.237577639751553, recent: 9.587064676616915\n",
      "Episode: 644, steps: 11, reward: 11.0, average: 10.23875968992248, recent: 9.587064676616915\n",
      "Episode: 645, steps: 9, reward: 9.0, average: 10.236842105263158, recent: 9.582089552238806\n",
      "Episode: 646, steps: 10, reward: 10.0, average: 10.236476043276662, recent: 9.587064676616915\n",
      "Episode: 647, steps: 10, reward: 10.0, average: 10.23611111111111, recent: 9.592039800995025\n",
      "Episode: 648, steps: 9, reward: 9.0, average: 10.234206471494607, recent: 9.587064676616915\n",
      "Episode: 649, steps: 9, reward: 9.0, average: 10.232307692307693, recent: 9.587064676616915\n",
      "Episode: 650, steps: 10, reward: 10.0, average: 10.23195084485407, recent: 9.597014925373134\n",
      "loss:  72.03418\n",
      "Episode: 651, steps: 9, reward: 9.0, average: 10.230061349693251, recent: 9.597014925373134\n",
      "Episode: 652, steps: 9, reward: 9.0, average: 10.228177641653906, recent: 9.592039800995025\n",
      "Episode: 653, steps: 8, reward: 8.0, average: 10.224770642201834, recent: 9.587064676616915\n",
      "Episode: 654, steps: 10, reward: 10.0, average: 10.224427480916031, recent: 9.592039800995025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 655, steps: 10, reward: 10.0, average: 10.224085365853659, recent: 9.587064676616915\n",
      "Episode: 656, steps: 10, reward: 10.0, average: 10.223744292237443, recent: 9.587064676616915\n",
      "Episode: 657, steps: 8, reward: 8.0, average: 10.220364741641337, recent: 9.572139303482587\n",
      "Episode: 658, steps: 11, reward: 11.0, average: 10.22154779969651, recent: 9.577114427860696\n",
      "Episode: 659, steps: 9, reward: 9.0, average: 10.219696969696969, recent: 9.572139303482587\n",
      "Episode: 660, steps: 10, reward: 10.0, average: 10.219364599092284, recent: 9.577114427860696\n",
      "loss:  303.84222\n",
      "Episode: 661, steps: 8, reward: 8.0, average: 10.216012084592146, recent: 9.562189054726367\n",
      "Episode: 662, steps: 9, reward: 9.0, average: 10.21417797888386, recent: 9.562189054726367\n",
      "Episode: 663, steps: 10, reward: 10.0, average: 10.213855421686747, recent: 9.567164179104477\n",
      "Episode: 664, steps: 10, reward: 10.0, average: 10.213533834586466, recent: 9.572139303482587\n",
      "Episode: 665, steps: 10, reward: 10.0, average: 10.213213213213214, recent: 9.572139303482587\n",
      "Episode: 666, steps: 10, reward: 10.0, average: 10.212893553223388, recent: 9.567164179104477\n",
      "Episode: 667, steps: 10, reward: 10.0, average: 10.2125748502994, recent: 9.572139303482587\n",
      "Episode: 668, steps: 10, reward: 10.0, average: 10.212257100149477, recent: 9.572139303482587\n",
      "Episode: 669, steps: 9, reward: 9.0, average: 10.210447761194029, recent: 9.567164179104477\n",
      "Episode: 670, steps: 8, reward: 8.0, average: 10.20715350223547, recent: 9.562189054726367\n",
      "loss:  176.65602\n",
      "Episode: 671, steps: 10, reward: 10.0, average: 10.206845238095237, recent: 9.562189054726367\n",
      "Episode: 672, steps: 9, reward: 9.0, average: 10.205052005943536, recent: 9.562189054726367\n",
      "Episode: 673, steps: 10, reward: 10.0, average: 10.204747774480712, recent: 9.567164179104477\n",
      "Episode: 674, steps: 12, reward: 12.0, average: 10.207407407407407, recent: 9.572139303482587\n",
      "Episode: 675, steps: 9, reward: 9.0, average: 10.205621301775148, recent: 9.567164179104477\n",
      "Episode: 676, steps: 9, reward: 9.0, average: 10.20384047267356, recent: 9.562189054726367\n",
      "Episode: 677, steps: 10, reward: 10.0, average: 10.20353982300885, recent: 9.567164179104477\n",
      "Episode: 678, steps: 9, reward: 9.0, average: 10.201767304860088, recent: 9.562189054726367\n",
      "Episode: 679, steps: 8, reward: 8.0, average: 10.198529411764707, recent: 9.552238805970148\n",
      "Episode: 680, steps: 10, reward: 10.0, average: 10.198237885462555, recent: 9.562189054726367\n",
      "loss:  211.15712\n",
      "Episode: 681, steps: 10, reward: 10.0, average: 10.197947214076246, recent: 9.557213930348258\n",
      "Episode: 682, steps: 10, reward: 10.0, average: 10.197657393850658, recent: 9.562189054726367\n",
      "Episode: 683, steps: 9, reward: 9.0, average: 10.195906432748538, recent: 9.552238805970148\n",
      "Episode: 684, steps: 9, reward: 9.0, average: 10.194160583941606, recent: 9.54726368159204\n",
      "Episode: 685, steps: 9, reward: 9.0, average: 10.192419825072886, recent: 9.54726368159204\n",
      "Episode: 686, steps: 8, reward: 8.0, average: 10.189228529839884, recent: 9.537313432835822\n",
      "Episode: 687, steps: 10, reward: 10.0, average: 10.188953488372093, recent: 9.542288557213931\n",
      "Episode: 688, steps: 10, reward: 10.0, average: 10.18867924528302, recent: 9.54726368159204\n",
      "Episode: 689, steps: 9, reward: 9.0, average: 10.18695652173913, recent: 9.542288557213931\n",
      "Episode: 690, steps: 8, reward: 8.0, average: 10.183791606367583, recent: 9.532338308457712\n",
      "loss:  0.68166363\n",
      "Episode: 691, steps: 10, reward: 10.0, average: 10.183526011560694, recent: 9.532338308457712\n",
      "Episode: 692, steps: 10, reward: 10.0, average: 10.183261183261184, recent: 9.537313432835822\n",
      "Episode: 693, steps: 10, reward: 10.0, average: 10.182997118155619, recent: 9.54726368159204\n",
      "Episode: 694, steps: 9, reward: 9.0, average: 10.181294964028776, recent: 9.537313432835822\n",
      "Episode: 695, steps: 10, reward: 10.0, average: 10.181034482758621, recent: 9.542288557213931\n",
      "Episode: 696, steps: 8, reward: 8.0, average: 10.17790530846485, recent: 9.537313432835822\n",
      "Episode: 697, steps: 10, reward: 10.0, average: 10.177650429799426, recent: 9.542288557213931\n",
      "Episode: 698, steps: 9, reward: 9.0, average: 10.17596566523605, recent: 9.54726368159204\n",
      "Episode: 699, steps: 8, reward: 8.0, average: 10.172857142857143, recent: 9.542288557213931\n",
      "Episode: 700, steps: 9, reward: 9.0, average: 10.171184022824537, recent: 9.537313432835822\n",
      "loss:  110.74563\n",
      "Episode: 701, steps: 8, reward: 8.0, average: 10.168091168091168, recent: 9.527363184079602\n",
      "Episode: 702, steps: 8, reward: 8.0, average: 10.165007112375534, recent: 9.517412935323383\n",
      "Episode: 703, steps: 12, reward: 12.0, average: 10.167613636363637, recent: 9.532338308457712\n",
      "Episode: 704, steps: 11, reward: 11.0, average: 10.168794326241136, recent: 9.542288557213931\n",
      "Episode: 705, steps: 10, reward: 10.0, average: 10.168555240793202, recent: 9.542288557213931\n",
      "Episode: 706, steps: 9, reward: 9.0, average: 10.166902404526168, recent: 9.532338308457712\n",
      "Episode: 707, steps: 10, reward: 10.0, average: 10.166666666666666, recent: 9.542288557213931\n",
      "Episode: 708, steps: 10, reward: 10.0, average: 10.166431593794076, recent: 9.542288557213931\n",
      "Episode: 709, steps: 10, reward: 10.0, average: 10.16619718309859, recent: 9.542288557213931\n",
      "Episode: 710, steps: 9, reward: 9.0, average: 10.164556962025317, recent: 9.542288557213931\n",
      "loss:  0.7500674\n",
      "Episode: 711, steps: 11, reward: 11.0, average: 10.165730337078651, recent: 9.557213930348258\n",
      "Episode: 712, steps: 9, reward: 9.0, average: 10.164095371669005, recent: 9.552238805970148\n",
      "Episode: 713, steps: 9, reward: 9.0, average: 10.162464985994397, recent: 9.54726368159204\n",
      "Episode: 714, steps: 10, reward: 10.0, average: 10.162237762237762, recent: 9.552238805970148\n",
      "Episode: 715, steps: 9, reward: 9.0, average: 10.160614525139664, recent: 9.537313432835822\n",
      "Episode: 716, steps: 10, reward: 10.0, average: 10.160390516039051, recent: 9.537313432835822\n",
      "Episode: 717, steps: 8, reward: 8.0, average: 10.157381615598887, recent: 9.527363184079602\n",
      "Episode: 718, steps: 9, reward: 9.0, average: 10.155771905424201, recent: 9.527363184079602\n",
      "Episode: 719, steps: 9, reward: 9.0, average: 10.154166666666667, recent: 9.522388059701493\n",
      "Episode: 720, steps: 10, reward: 10.0, average: 10.153952843273231, recent: 9.527363184079602\n",
      "loss:  3095.8618\n",
      "Episode: 721, steps: 10, reward: 10.0, average: 10.153739612188366, recent: 9.512437810945274\n",
      "Episode: 722, steps: 10, reward: 10.0, average: 10.153526970954356, recent: 9.512437810945274\n",
      "Episode: 723, steps: 10, reward: 10.0, average: 10.153314917127071, recent: 9.517412935323383\n",
      "Episode: 724, steps: 9, reward: 9.0, average: 10.151724137931035, recent: 9.522388059701493\n",
      "Episode: 725, steps: 10, reward: 10.0, average: 10.151515151515152, recent: 9.527363184079602\n",
      "Episode: 726, steps: 9, reward: 9.0, average: 10.149931224209078, recent: 9.527363184079602\n",
      "Episode: 727, steps: 10, reward: 10.0, average: 10.149725274725276, recent: 9.532338308457712\n",
      "Episode: 728, steps: 11, reward: 11.0, average: 10.150891632373114, recent: 9.542288557213931\n",
      "Episode: 729, steps: 9, reward: 9.0, average: 10.14931506849315, recent: 9.537313432835822\n",
      "Episode: 730, steps: 10, reward: 10.0, average: 10.149110807113543, recent: 9.537313432835822\n",
      "loss:  118.567825\n",
      "Episode: 731, steps: 8, reward: 8.0, average: 10.146174863387978, recent: 9.532338308457712\n",
      "Episode: 732, steps: 9, reward: 9.0, average: 10.144611186903138, recent: 9.537313432835822\n",
      "Episode: 733, steps: 9, reward: 9.0, average: 10.143051771117166, recent: 9.537313432835822\n",
      "Episode: 734, steps: 10, reward: 10.0, average: 10.142857142857142, recent: 9.537313432835822\n",
      "Episode: 735, steps: 10, reward: 10.0, average: 10.142663043478262, recent: 9.542288557213931\n",
      "Episode: 736, steps: 10, reward: 10.0, average: 10.14246947082768, recent: 9.542288557213931\n",
      "Episode: 737, steps: 9, reward: 9.0, average: 10.140921409214092, recent: 9.54726368159204\n",
      "Episode: 738, steps: 10, reward: 10.0, average: 10.140730717185386, recent: 9.552238805970148\n",
      "Episode: 739, steps: 10, reward: 10.0, average: 10.14054054054054, recent: 9.557213930348258\n",
      "Episode: 740, steps: 10, reward: 10.0, average: 10.140350877192983, recent: 9.557213930348258\n",
      "loss:  16.912266\n",
      "Episode: 741, steps: 9, reward: 9.0, average: 10.138814016172507, recent: 9.552238805970148\n",
      "Episode: 742, steps: 9, reward: 9.0, average: 10.13728129205922, recent: 9.552238805970148\n",
      "Episode: 743, steps: 10, reward: 10.0, average: 10.137096774193548, recent: 9.552238805970148\n",
      "Episode: 744, steps: 9, reward: 9.0, average: 10.135570469798658, recent: 9.54726368159204\n",
      "Episode: 745, steps: 10, reward: 10.0, average: 10.13538873994638, recent: 9.552238805970148\n",
      "Episode: 746, steps: 10, reward: 10.0, average: 10.13520749665328, recent: 9.54726368159204\n",
      "Episode: 747, steps: 9, reward: 9.0, average: 10.133689839572192, recent: 9.542288557213931\n",
      "Episode: 748, steps: 10, reward: 10.0, average: 10.13351134846462, recent: 9.537313432835822\n",
      "Episode: 749, steps: 10, reward: 10.0, average: 10.133333333333333, recent: 9.537313432835822\n",
      "Episode: 750, steps: 10, reward: 10.0, average: 10.133155792276964, recent: 9.537313432835822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  458.7548\n",
      "Episode: 751, steps: 11, reward: 11.0, average: 10.134308510638299, recent: 9.542288557213931\n",
      "Episode: 752, steps: 8, reward: 8.0, average: 10.131474103585658, recent: 9.532338308457712\n",
      "Episode: 753, steps: 9, reward: 9.0, average: 10.12997347480106, recent: 9.537313432835822\n",
      "Episode: 754, steps: 10, reward: 10.0, average: 10.129801324503312, recent: 9.537313432835822\n",
      "Episode: 755, steps: 9, reward: 9.0, average: 10.128306878306878, recent: 9.527363184079602\n",
      "Episode: 756, steps: 12, reward: 12.0, average: 10.130779392338177, recent: 9.542288557213931\n",
      "Episode: 757, steps: 8, reward: 8.0, average: 10.12796833773087, recent: 9.542288557213931\n",
      "Episode: 758, steps: 8, reward: 8.0, average: 10.125164690382082, recent: 9.537313432835822\n",
      "Episode: 759, steps: 9, reward: 9.0, average: 10.123684210526315, recent: 9.542288557213931\n",
      "Episode: 760, steps: 9, reward: 9.0, average: 10.122207621550592, recent: 9.542288557213931\n",
      "loss:  402.4401\n",
      "Episode: 761, steps: 10, reward: 10.0, average: 10.122047244094489, recent: 9.54726368159204\n",
      "Episode: 762, steps: 10, reward: 10.0, average: 10.121887287024903, recent: 9.552238805970148\n",
      "Episode: 763, steps: 9, reward: 9.0, average: 10.120418848167539, recent: 9.542288557213931\n",
      "Episode: 764, steps: 11, reward: 11.0, average: 10.12156862745098, recent: 9.54726368159204\n",
      "Episode: 765, steps: 10, reward: 10.0, average: 10.121409921671018, recent: 9.54726368159204\n",
      "Episode: 766, steps: 9, reward: 9.0, average: 10.119947848761408, recent: 9.54726368159204\n",
      "Episode: 767, steps: 9, reward: 9.0, average: 10.118489583333334, recent: 9.54726368159204\n",
      "Episode: 768, steps: 10, reward: 10.0, average: 10.118335500650195, recent: 9.557213930348258\n",
      "Episode: 769, steps: 8, reward: 8.0, average: 10.115584415584415, recent: 9.542288557213931\n",
      "Episode: 770, steps: 11, reward: 11.0, average: 10.116731517509727, recent: 9.54726368159204\n",
      "loss:  91.399994\n",
      "Episode: 771, steps: 11, reward: 11.0, average: 10.117875647668393, recent: 9.562189054726367\n",
      "Episode: 772, steps: 8, reward: 8.0, average: 10.115135834411385, recent: 9.557213930348258\n",
      "Episode: 773, steps: 10, reward: 10.0, average: 10.11498708010336, recent: 9.557213930348258\n",
      "Episode: 774, steps: 8, reward: 8.0, average: 10.112258064516128, recent: 9.542288557213931\n",
      "Episode: 775, steps: 9, reward: 9.0, average: 10.110824742268042, recent: 9.542288557213931\n",
      "Episode: 776, steps: 10, reward: 10.0, average: 10.110682110682111, recent: 9.542288557213931\n",
      "Episode: 777, steps: 9, reward: 9.0, average: 10.109254498714654, recent: 9.542288557213931\n",
      "Episode: 778, steps: 10, reward: 10.0, average: 10.109114249037226, recent: 9.537313432835822\n",
      "Episode: 779, steps: 11, reward: 11.0, average: 10.11025641025641, recent: 9.542288557213931\n",
      "Episode: 780, steps: 9, reward: 9.0, average: 10.108834827144687, recent: 9.537313432835822\n",
      "loss:  1662.8478\n",
      "Episode: 781, steps: 9, reward: 9.0, average: 10.107416879795396, recent: 9.537313432835822\n",
      "Episode: 782, steps: 10, reward: 10.0, average: 10.10727969348659, recent: 9.542288557213931\n",
      "Episode: 783, steps: 9, reward: 9.0, average: 10.105867346938776, recent: 9.537313432835822\n",
      "Episode: 784, steps: 9, reward: 9.0, average: 10.104458598726115, recent: 9.532338308457712\n",
      "Episode: 785, steps: 9, reward: 9.0, average: 10.103053435114504, recent: 9.522388059701493\n",
      "Episode: 786, steps: 10, reward: 10.0, average: 10.10292249047014, recent: 9.532338308457712\n",
      "Episode: 787, steps: 10, reward: 10.0, average: 10.102791878172589, recent: 9.537313432835822\n",
      "Episode: 788, steps: 9, reward: 9.0, average: 10.101394169835235, recent: 9.527363184079602\n",
      "Episode: 789, steps: 11, reward: 11.0, average: 10.10253164556962, recent: 9.532338308457712\n",
      "Episode: 790, steps: 10, reward: 10.0, average: 10.102402022756005, recent: 9.542288557213931\n",
      "loss:  304.48102\n",
      "Episode: 791, steps: 10, reward: 10.0, average: 10.102272727272727, recent: 9.54726368159204\n",
      "Episode: 792, steps: 10, reward: 10.0, average: 10.102143757881462, recent: 9.54726368159204\n",
      "Episode: 793, steps: 9, reward: 9.0, average: 10.100755667506297, recent: 9.542288557213931\n",
      "Episode: 794, steps: 10, reward: 10.0, average: 10.10062893081761, recent: 9.54726368159204\n",
      "Episode: 795, steps: 8, reward: 8.0, average: 10.097989949748744, recent: 9.54726368159204\n",
      "Episode: 796, steps: 8, reward: 8.0, average: 10.095357590966122, recent: 9.537313432835822\n",
      "Episode: 797, steps: 9, reward: 9.0, average: 10.093984962406015, recent: 9.537313432835822\n",
      "Episode: 798, steps: 8, reward: 8.0, average: 10.091364205256571, recent: 9.532338308457712\n",
      "Episode: 799, steps: 10, reward: 10.0, average: 10.09125, recent: 9.542288557213931\n",
      "Episode: 800, steps: 9, reward: 9.0, average: 10.089887640449438, recent: 9.537313432835822\n",
      "loss:  269.59775\n",
      "Episode: 801, steps: 10, reward: 10.0, average: 10.089775561097257, recent: 9.537313432835822\n",
      "Episode: 802, steps: 10, reward: 10.0, average: 10.089663760896638, recent: 9.542288557213931\n",
      "Episode: 803, steps: 10, reward: 10.0, average: 10.08955223880597, recent: 9.537313432835822\n",
      "Episode: 804, steps: 10, reward: 10.0, average: 10.08944099378882, recent: 9.537313432835822\n",
      "Episode: 805, steps: 8, reward: 8.0, average: 10.086848635235732, recent: 9.527363184079602\n",
      "Episode: 806, steps: 10, reward: 10.0, average: 10.086741016109046, recent: 9.522388059701493\n",
      "Episode: 807, steps: 10, reward: 10.0, average: 10.086633663366337, recent: 9.532338308457712\n",
      "Episode: 808, steps: 10, reward: 10.0, average: 10.086526576019777, recent: 9.542288557213931\n",
      "Episode: 809, steps: 10, reward: 10.0, average: 10.08641975308642, recent: 9.537313432835822\n",
      "Episode: 810, steps: 10, reward: 10.0, average: 10.086313193588163, recent: 9.532338308457712\n",
      "loss:  31.263254\n",
      "Episode: 811, steps: 9, reward: 9.0, average: 10.084975369458128, recent: 9.527363184079602\n",
      "Episode: 812, steps: 10, reward: 10.0, average: 10.084870848708487, recent: 9.532338308457712\n",
      "Episode: 813, steps: 9, reward: 9.0, average: 10.083538083538084, recent: 9.537313432835822\n",
      "Episode: 814, steps: 10, reward: 10.0, average: 10.083435582822085, recent: 9.537313432835822\n",
      "Episode: 815, steps: 10, reward: 10.0, average: 10.083333333333334, recent: 9.537313432835822\n",
      "Episode: 816, steps: 10, reward: 10.0, average: 10.083231334149326, recent: 9.542288557213931\n",
      "Episode: 817, steps: 9, reward: 9.0, average: 10.081907090464547, recent: 9.542288557213931\n",
      "Episode: 818, steps: 9, reward: 9.0, average: 10.08058608058608, recent: 9.542288557213931\n",
      "Episode: 819, steps: 10, reward: 10.0, average: 10.080487804878048, recent: 9.532338308457712\n",
      "Episode: 820, steps: 9, reward: 9.0, average: 10.07917174177832, recent: 9.527363184079602\n",
      "loss:  272.32114\n",
      "Episode: 821, steps: 9, reward: 9.0, average: 10.077858880778589, recent: 9.527363184079602\n",
      "Episode: 822, steps: 9, reward: 9.0, average: 10.076549210206561, recent: 9.512437810945274\n",
      "Episode: 823, steps: 10, reward: 10.0, average: 10.076456310679612, recent: 9.512437810945274\n",
      "Episode: 824, steps: 12, reward: 12.0, average: 10.078787878787878, recent: 9.532338308457712\n",
      "Episode: 825, steps: 9, reward: 9.0, average: 10.077481840193705, recent: 9.522388059701493\n",
      "Episode: 826, steps: 11, reward: 11.0, average: 10.078597339782347, recent: 9.527363184079602\n",
      "Episode: 827, steps: 9, reward: 9.0, average: 10.077294685990339, recent: 9.527363184079602\n",
      "Episode: 828, steps: 10, reward: 10.0, average: 10.077201447527141, recent: 9.527363184079602\n",
      "Episode: 829, steps: 10, reward: 10.0, average: 10.07710843373494, recent: 9.527363184079602\n",
      "Episode: 830, steps: 10, reward: 10.0, average: 10.077015643802648, recent: 9.532338308457712\n",
      "loss:  530.15436\n",
      "Episode: 831, steps: 10, reward: 10.0, average: 10.076923076923077, recent: 9.532338308457712\n",
      "Episode: 832, steps: 9, reward: 9.0, average: 10.07563025210084, recent: 9.527363184079602\n",
      "Episode: 833, steps: 9, reward: 9.0, average: 10.074340527577938, recent: 9.522388059701493\n",
      "Episode: 834, steps: 8, reward: 8.0, average: 10.071856287425149, recent: 9.522388059701493\n",
      "Episode: 835, steps: 9, reward: 9.0, average: 10.070574162679426, recent: 9.517412935323383\n",
      "Episode: 836, steps: 10, reward: 10.0, average: 10.070489844683394, recent: 9.522388059701493\n",
      "Episode: 837, steps: 10, reward: 10.0, average: 10.070405727923628, recent: 9.517412935323383\n",
      "Episode: 838, steps: 10, reward: 10.0, average: 10.070321811680571, recent: 9.522388059701493\n",
      "Episode: 839, steps: 10, reward: 10.0, average: 10.070238095238095, recent: 9.522388059701493\n",
      "Episode: 840, steps: 11, reward: 11.0, average: 10.071343638525565, recent: 9.527363184079602\n",
      "loss:  0.0079978695\n",
      "Episode: 841, steps: 10, reward: 10.0, average: 10.07125890736342, recent: 9.527363184079602\n",
      "Episode: 842, steps: 9, reward: 9.0, average: 10.069988137603795, recent: 9.527363184079602\n",
      "Episode: 843, steps: 10, reward: 10.0, average: 10.069905213270141, recent: 9.522388059701493\n",
      "Episode: 844, steps: 8, reward: 8.0, average: 10.067455621301775, recent: 9.522388059701493\n",
      "Episode: 845, steps: 8, reward: 8.0, average: 10.06501182033097, recent: 9.507462686567164\n",
      "Episode: 846, steps: 9, reward: 9.0, average: 10.06375442739079, recent: 9.507462686567164\n",
      "Episode: 847, steps: 9, reward: 9.0, average: 10.0625, recent: 9.502487562189055\n",
      "Episode: 848, steps: 9, reward: 9.0, average: 10.061248527679624, recent: 9.497512437810945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 849, steps: 11, reward: 11.0, average: 10.06235294117647, recent: 9.507462686567164\n",
      "Episode: 850, steps: 9, reward: 9.0, average: 10.061104582843713, recent: 9.507462686567164\n",
      "loss:  3.2134376\n",
      "Episode: 851, steps: 10, reward: 10.0, average: 10.061032863849766, recent: 9.507462686567164\n",
      "Episode: 852, steps: 9, reward: 9.0, average: 10.05978898007034, recent: 9.507462686567164\n",
      "Episode: 853, steps: 9, reward: 9.0, average: 10.058548009367682, recent: 9.507462686567164\n",
      "Episode: 854, steps: 10, reward: 10.0, average: 10.058479532163743, recent: 9.517412935323383\n",
      "Episode: 855, steps: 9, reward: 9.0, average: 10.057242990654206, recent: 9.512437810945274\n",
      "Episode: 856, steps: 10, reward: 10.0, average: 10.057176196032673, recent: 9.512437810945274\n",
      "Episode: 857, steps: 10, reward: 10.0, average: 10.057109557109557, recent: 9.512437810945274\n",
      "Episode: 858, steps: 8, reward: 8.0, average: 10.054714784633294, recent: 9.512437810945274\n",
      "Episode: 859, steps: 10, reward: 10.0, average: 10.054651162790698, recent: 9.507462686567164\n",
      "Episode: 860, steps: 11, reward: 11.0, average: 10.05574912891986, recent: 9.517412935323383\n",
      "loss:  168.19385\n",
      "Episode: 861, steps: 10, reward: 10.0, average: 10.055684454756381, recent: 9.517412935323383\n",
      "Episode: 862, steps: 10, reward: 10.0, average: 10.055619930475087, recent: 9.527363184079602\n",
      "Episode: 863, steps: 10, reward: 10.0, average: 10.055555555555555, recent: 9.532338308457712\n",
      "Episode: 864, steps: 9, reward: 9.0, average: 10.054335260115607, recent: 9.527363184079602\n",
      "Episode: 865, steps: 12, reward: 12.0, average: 10.056581986143186, recent: 9.537313432835822\n",
      "Episode: 866, steps: 9, reward: 9.0, average: 10.055363321799309, recent: 9.532338308457712\n",
      "Episode: 867, steps: 10, reward: 10.0, average: 10.055299539170507, recent: 9.532338308457712\n",
      "Episode: 868, steps: 9, reward: 9.0, average: 10.054085155350979, recent: 9.527363184079602\n",
      "Episode: 869, steps: 12, reward: 12.0, average: 10.056321839080459, recent: 9.537313432835822\n",
      "Episode: 870, steps: 9, reward: 9.0, average: 10.055109070034444, recent: 9.537313432835822\n",
      "loss:  100.67412\n",
      "Episode: 871, steps: 9, reward: 9.0, average: 10.053899082568808, recent: 9.542288557213931\n",
      "Episode: 872, steps: 8, reward: 8.0, average: 10.051546391752577, recent: 9.532338308457712\n",
      "Episode: 873, steps: 10, reward: 10.0, average: 10.051487414187642, recent: 9.537313432835822\n",
      "Episode: 874, steps: 9, reward: 9.0, average: 10.050285714285714, recent: 9.532338308457712\n",
      "Episode: 875, steps: 9, reward: 9.0, average: 10.049086757990867, recent: 9.517412935323383\n",
      "Episode: 876, steps: 10, reward: 10.0, average: 10.04903078677309, recent: 9.522388059701493\n",
      "Episode: 877, steps: 10, reward: 10.0, average: 10.048974943052391, recent: 9.527363184079602\n",
      "Episode: 878, steps: 9, reward: 9.0, average: 10.04778156996587, recent: 9.522388059701493\n",
      "Episode: 879, steps: 10, reward: 10.0, average: 10.047727272727272, recent: 9.527363184079602\n",
      "Episode: 880, steps: 10, reward: 10.0, average: 10.04767309875142, recent: 9.537313432835822\n",
      "loss:  17.065567\n",
      "Episode: 881, steps: 9, reward: 9.0, average: 10.046485260770975, recent: 9.532338308457712\n",
      "Episode: 882, steps: 9, reward: 9.0, average: 10.045300113250283, recent: 9.527363184079602\n",
      "Episode: 883, steps: 10, reward: 10.0, average: 10.04524886877828, recent: 9.527363184079602\n",
      "Episode: 884, steps: 9, reward: 9.0, average: 10.04406779661017, recent: 9.527363184079602\n",
      "Episode: 885, steps: 10, reward: 10.0, average: 10.044018058690744, recent: 9.532338308457712\n",
      "Episode: 886, steps: 10, reward: 10.0, average: 10.043968432919955, recent: 9.537313432835822\n",
      "Episode: 887, steps: 9, reward: 9.0, average: 10.042792792792794, recent: 9.542288557213931\n",
      "Episode: 888, steps: 9, reward: 9.0, average: 10.041619797525309, recent: 9.537313432835822\n",
      "Episode: 889, steps: 9, reward: 9.0, average: 10.040449438202247, recent: 9.532338308457712\n",
      "Episode: 890, steps: 9, reward: 9.0, average: 10.039281705948373, recent: 9.532338308457712\n",
      "loss:  99.87726\n",
      "Episode: 891, steps: 10, reward: 10.0, average: 10.039237668161435, recent: 9.542288557213931\n",
      "Episode: 892, steps: 9, reward: 9.0, average: 10.038073908174692, recent: 9.537313432835822\n",
      "Episode: 893, steps: 9, reward: 9.0, average: 10.036912751677852, recent: 9.532338308457712\n",
      "Episode: 894, steps: 10, reward: 10.0, average: 10.036871508379889, recent: 9.532338308457712\n",
      "Episode: 895, steps: 9, reward: 9.0, average: 10.035714285714286, recent: 9.532338308457712\n",
      "Episode: 896, steps: 8, reward: 8.0, average: 10.033444816053512, recent: 9.522388059701493\n",
      "Episode: 897, steps: 10, reward: 10.0, average: 10.033407572383073, recent: 9.532338308457712\n",
      "Episode: 898, steps: 10, reward: 10.0, average: 10.03337041156841, recent: 9.532338308457712\n",
      "Episode: 899, steps: 10, reward: 10.0, average: 10.033333333333333, recent: 9.537313432835822\n",
      "Episode: 900, steps: 9, reward: 9.0, average: 10.032186459489456, recent: 9.542288557213931\n",
      "loss:  166.38667\n",
      "Episode: 901, steps: 10, reward: 10.0, average: 10.032150776053214, recent: 9.54726368159204\n",
      "Episode: 902, steps: 9, reward: 9.0, average: 10.031007751937985, recent: 9.552238805970148\n",
      "Episode: 903, steps: 10, reward: 10.0, average: 10.030973451327434, recent: 9.562189054726367\n",
      "Episode: 904, steps: 8, reward: 8.0, average: 10.028729281767955, recent: 9.542288557213931\n",
      "Episode: 905, steps: 9, reward: 9.0, average: 10.027593818984547, recent: 9.532338308457712\n",
      "Episode: 906, steps: 10, reward: 10.0, average: 10.027563395810365, recent: 9.532338308457712\n",
      "Episode: 907, steps: 9, reward: 9.0, average: 10.026431718061675, recent: 9.532338308457712\n",
      "Episode: 908, steps: 10, reward: 10.0, average: 10.026402640264026, recent: 9.532338308457712\n",
      "Episode: 909, steps: 11, reward: 11.0, average: 10.027472527472527, recent: 9.537313432835822\n",
      "Episode: 910, steps: 9, reward: 9.0, average: 10.026344676180022, recent: 9.532338308457712\n",
      "loss:  327.49796\n",
      "Episode: 911, steps: 11, reward: 11.0, average: 10.027412280701755, recent: 9.542288557213931\n",
      "Episode: 912, steps: 10, reward: 10.0, average: 10.02738225629792, recent: 9.537313432835822\n",
      "Episode: 913, steps: 10, reward: 10.0, average: 10.027352297592998, recent: 9.542288557213931\n",
      "Episode: 914, steps: 9, reward: 9.0, average: 10.026229508196721, recent: 9.542288557213931\n",
      "Episode: 915, steps: 9, reward: 9.0, average: 10.025109170305678, recent: 9.537313432835822\n",
      "Episode: 916, steps: 10, reward: 10.0, average: 10.025081788440566, recent: 9.542288557213931\n",
      "Episode: 917, steps: 10, reward: 10.0, average: 10.025054466230937, recent: 9.542288557213931\n",
      "Episode: 918, steps: 10, reward: 10.0, average: 10.025027203482045, recent: 9.552238805970148\n",
      "Episode: 919, steps: 8, reward: 8.0, average: 10.022826086956522, recent: 9.54726368159204\n",
      "Episode: 920, steps: 9, reward: 9.0, average: 10.02171552660152, recent: 9.54726368159204\n",
      "loss:  225.65732\n",
      "Episode: 921, steps: 9, reward: 9.0, average: 10.02060737527115, recent: 9.542288557213931\n",
      "Episode: 922, steps: 10, reward: 10.0, average: 10.020585048754063, recent: 9.542288557213931\n",
      "Episode: 923, steps: 8, reward: 8.0, average: 10.018398268398268, recent: 9.532338308457712\n",
      "Episode: 924, steps: 9, reward: 9.0, average: 10.017297297297297, recent: 9.527363184079602\n",
      "Episode: 925, steps: 8, reward: 8.0, average: 10.01511879049676, recent: 9.522388059701493\n",
      "Episode: 926, steps: 10, reward: 10.0, average: 10.015102481121898, recent: 9.522388059701493\n",
      "Episode: 927, steps: 9, reward: 9.0, average: 10.014008620689655, recent: 9.522388059701493\n",
      "Episode: 928, steps: 10, reward: 10.0, average: 10.013993541442412, recent: 9.522388059701493\n",
      "Episode: 929, steps: 9, reward: 9.0, average: 10.012903225806452, recent: 9.512437810945274\n",
      "Episode: 930, steps: 9, reward: 9.0, average: 10.011815252416756, recent: 9.512437810945274\n",
      "loss:  27.037916\n",
      "Episode: 931, steps: 10, reward: 10.0, average: 10.011802575107296, recent: 9.512437810945274\n",
      "Episode: 932, steps: 9, reward: 9.0, average: 10.010718113612004, recent: 9.517412935323383\n",
      "Episode: 933, steps: 9, reward: 9.0, average: 10.009635974304068, recent: 9.517412935323383\n",
      "Episode: 934, steps: 11, reward: 11.0, average: 10.010695187165775, recent: 9.527363184079602\n",
      "Episode: 935, steps: 9, reward: 9.0, average: 10.009615384615385, recent: 9.522388059701493\n",
      "Episode: 936, steps: 10, reward: 10.0, average: 10.009605122732124, recent: 9.522388059701493\n",
      "Episode: 937, steps: 10, reward: 10.0, average: 10.00959488272921, recent: 9.522388059701493\n",
      "Episode: 938, steps: 8, reward: 8.0, average: 10.007454739084132, recent: 9.517412935323383\n",
      "Episode: 939, steps: 9, reward: 9.0, average: 10.006382978723405, recent: 9.512437810945274\n",
      "Episode: 940, steps: 9, reward: 9.0, average: 10.005313496280552, recent: 9.507462686567164\n",
      "loss:  2587.2693\n",
      "Episode: 941, steps: 9, reward: 9.0, average: 10.004246284501061, recent: 9.502487562189055\n",
      "Episode: 942, steps: 10, reward: 10.0, average: 10.00424178154825, recent: 9.507462686567164\n",
      "Episode: 943, steps: 10, reward: 10.0, average: 10.004237288135593, recent: 9.512437810945274\n",
      "Episode: 944, steps: 10, reward: 10.0, average: 10.004232804232805, recent: 9.512437810945274\n",
      "Episode: 945, steps: 9, reward: 9.0, average: 10.003171247357294, recent: 9.512437810945274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 946, steps: 8, reward: 8.0, average: 10.001055966209082, recent: 9.502487562189055\n",
      "Episode: 947, steps: 8, reward: 8.0, average: 9.998945147679326, recent: 9.492537313432836\n",
      "Episode: 948, steps: 10, reward: 10.0, average: 9.998946259220231, recent: 9.497512437810945\n",
      "Episode: 949, steps: 11, reward: 11.0, average: 10.0, recent: 9.502487562189055\n",
      "Episode: 950, steps: 10, reward: 10.0, average: 10.0, recent: 9.502487562189055\n",
      "loss:  130.37927\n",
      "Episode: 951, steps: 10, reward: 10.0, average: 10.0, recent: 9.502487562189055\n",
      "Episode: 952, steps: 9, reward: 9.0, average: 9.998950682056662, recent: 9.492537313432836\n",
      "Episode: 953, steps: 9, reward: 9.0, average: 9.9979035639413, recent: 9.497512437810945\n",
      "Episode: 954, steps: 10, reward: 10.0, average: 9.997905759162304, recent: 9.502487562189055\n",
      "Episode: 955, steps: 10, reward: 10.0, average: 9.997907949790795, recent: 9.502487562189055\n",
      "Episode: 956, steps: 9, reward: 9.0, average: 9.996865203761756, recent: 9.502487562189055\n",
      "Episode: 957, steps: 8, reward: 8.0, average: 9.994780793319416, recent: 9.482587064676617\n",
      "Episode: 958, steps: 10, reward: 10.0, average: 9.994786235662149, recent: 9.492537313432836\n",
      "Episode: 959, steps: 10, reward: 10.0, average: 9.994791666666666, recent: 9.502487562189055\n",
      "Episode: 960, steps: 10, reward: 10.0, average: 9.994797086368367, recent: 9.507462686567164\n",
      "loss:  54.311176\n",
      "Episode: 961, steps: 10, reward: 10.0, average: 9.994802494802494, recent: 9.512437810945274\n",
      "Episode: 962, steps: 8, reward: 8.0, average: 9.992731048805815, recent: 9.502487562189055\n",
      "Episode: 963, steps: 10, reward: 10.0, average: 9.992738589211617, recent: 9.502487562189055\n",
      "Episode: 964, steps: 9, reward: 9.0, average: 9.991709844559585, recent: 9.502487562189055\n",
      "Episode: 965, steps: 9, reward: 9.0, average: 9.990683229813664, recent: 9.492537313432836\n",
      "Episode: 966, steps: 10, reward: 10.0, average: 9.990692864529473, recent: 9.492537313432836\n",
      "Episode: 967, steps: 9, reward: 9.0, average: 9.989669421487603, recent: 9.492537313432836\n",
      "Episode: 968, steps: 9, reward: 9.0, average: 9.988648090815273, recent: 9.492537313432836\n",
      "Episode: 969, steps: 10, reward: 10.0, average: 9.988659793814433, recent: 9.492537313432836\n",
      "Episode: 970, steps: 10, reward: 10.0, average: 9.988671472708548, recent: 9.502487562189055\n",
      "loss:  255.85597\n",
      "Episode: 971, steps: 10, reward: 10.0, average: 9.988683127572017, recent: 9.497512437810945\n",
      "Episode: 972, steps: 9, reward: 9.0, average: 9.987667009249742, recent: 9.487562189054726\n",
      "Episode: 973, steps: 8, reward: 8.0, average: 9.985626283367557, recent: 9.487562189054726\n",
      "Episode: 974, steps: 11, reward: 11.0, average: 9.986666666666666, recent: 9.492537313432836\n",
      "Episode: 975, steps: 10, reward: 10.0, average: 9.986680327868852, recent: 9.502487562189055\n",
      "Episode: 976, steps: 9, reward: 9.0, average: 9.985670419651996, recent: 9.502487562189055\n",
      "Episode: 977, steps: 10, reward: 10.0, average: 9.985685071574641, recent: 9.502487562189055\n",
      "Episode: 978, steps: 10, reward: 10.0, average: 9.985699693564863, recent: 9.507462686567164\n",
      "Episode: 979, steps: 10, reward: 10.0, average: 9.985714285714286, recent: 9.507462686567164\n",
      "Episode: 980, steps: 10, reward: 10.0, average: 9.985728848114169, recent: 9.502487562189055\n",
      "loss:  0.3188838\n",
      "Episode: 981, steps: 8, reward: 8.0, average: 9.983706720977597, recent: 9.497512437810945\n",
      "Episode: 982, steps: 8, reward: 8.0, average: 9.981688708036623, recent: 9.492537313432836\n",
      "Episode: 983, steps: 10, reward: 10.0, average: 9.981707317073171, recent: 9.492537313432836\n",
      "Episode: 984, steps: 10, reward: 10.0, average: 9.981725888324872, recent: 9.497512437810945\n",
      "Episode: 985, steps: 10, reward: 10.0, average: 9.981744421906694, recent: 9.502487562189055\n",
      "Episode: 986, steps: 10, reward: 10.0, average: 9.98176291793313, recent: 9.507462686567164\n",
      "Episode: 987, steps: 9, reward: 9.0, average: 9.98076923076923, recent: 9.502487562189055\n",
      "Episode: 988, steps: 10, reward: 10.0, average: 9.980788675429727, recent: 9.502487562189055\n",
      "Episode: 989, steps: 10, reward: 10.0, average: 9.980808080808082, recent: 9.507462686567164\n",
      "Episode: 990, steps: 8, reward: 8.0, average: 9.978809283551968, recent: 9.492537313432836\n",
      "loss:  454.8642\n",
      "Episode: 991, steps: 10, reward: 10.0, average: 9.97883064516129, recent: 9.492537313432836\n",
      "Episode: 992, steps: 9, reward: 9.0, average: 9.977844914400805, recent: 9.487562189054726\n",
      "Episode: 993, steps: 9, reward: 9.0, average: 9.976861167002012, recent: 9.482587064676617\n",
      "Episode: 994, steps: 9, reward: 9.0, average: 9.975879396984924, recent: 9.482587064676617\n",
      "Episode: 995, steps: 9, reward: 9.0, average: 9.974899598393574, recent: 9.477611940298507\n",
      "Episode: 996, steps: 9, reward: 9.0, average: 9.973921765295888, recent: 9.482587064676617\n",
      "Episode: 997, steps: 10, reward: 10.0, average: 9.973947895791584, recent: 9.492537313432836\n",
      "Episode: 998, steps: 9, reward: 9.0, average: 9.972972972972974, recent: 9.492537313432836\n",
      "Episode: 999, steps: 9, reward: 9.0, average: 9.972, recent: 9.497512437810945\n",
      "Episode: 1000, steps: 10, reward: 10.0, average: 9.972027972027972, recent: 9.497512437810945\n",
      "loss:  310.02783\n",
      "Episode: 1001, steps: 11, reward: 11.0, average: 9.97305389221557, recent: 9.507462686567164\n",
      "Episode: 1002, steps: 9, reward: 9.0, average: 9.97208374875374, recent: 9.502487562189055\n",
      "Episode: 1003, steps: 10, reward: 10.0, average: 9.97211155378486, recent: 9.502487562189055\n",
      "Episode: 1004, steps: 10, reward: 10.0, average: 9.972139303482587, recent: 9.502487562189055\n",
      "Episode: 1005, steps: 10, reward: 10.0, average: 9.972166998011929, recent: 9.502487562189055\n",
      "Episode: 1006, steps: 10, reward: 10.0, average: 9.972194637537239, recent: 9.512437810945274\n",
      "Episode: 1007, steps: 9, reward: 9.0, average: 9.971230158730158, recent: 9.507462686567164\n",
      "Episode: 1008, steps: 10, reward: 10.0, average: 9.971258671952429, recent: 9.507462686567164\n",
      "Episode: 1009, steps: 10, reward: 10.0, average: 9.971287128712872, recent: 9.507462686567164\n",
      "Episode: 1010, steps: 8, reward: 8.0, average: 9.969337289812067, recent: 9.497512437810945\n",
      "loss:  104.7398\n",
      "Episode: 1011, steps: 9, reward: 9.0, average: 9.968379446640316, recent: 9.492537313432836\n",
      "Episode: 1012, steps: 9, reward: 9.0, average: 9.967423494570582, recent: 9.492537313432836\n",
      "Episode: 1013, steps: 8, reward: 8.0, average: 9.965483234714004, recent: 9.482587064676617\n",
      "Episode: 1014, steps: 10, reward: 10.0, average: 9.96551724137931, recent: 9.487562189054726\n",
      "Episode: 1015, steps: 10, reward: 10.0, average: 9.965551181102363, recent: 9.487562189054726\n",
      "Episode: 1016, steps: 8, reward: 8.0, average: 9.96361848574238, recent: 9.477611940298507\n",
      "Episode: 1017, steps: 8, reward: 8.0, average: 9.961689587426326, recent: 9.467661691542288\n",
      "Episode: 1018, steps: 10, reward: 10.0, average: 9.961727183513249, recent: 9.472636815920398\n",
      "Episode: 1019, steps: 10, reward: 10.0, average: 9.961764705882352, recent: 9.477611940298507\n",
      "Episode: 1020, steps: 9, reward: 9.0, average: 9.960822722820764, recent: 9.472636815920398\n",
      "loss:  55.38808\n",
      "Episode: 1021, steps: 9, reward: 9.0, average: 9.959882583170254, recent: 9.472636815920398\n",
      "Episode: 1022, steps: 10, reward: 10.0, average: 9.959921798631475, recent: 9.477611940298507\n",
      "Episode: 1023, steps: 11, reward: 11.0, average: 9.9609375, recent: 9.487562189054726\n",
      "Episode: 1024, steps: 9, reward: 9.0, average: 9.96, recent: 9.482587064676617\n",
      "Episode: 1025, steps: 10, reward: 10.0, average: 9.960038986354776, recent: 9.472636815920398\n",
      "Episode: 1026, steps: 10, reward: 10.0, average: 9.960077896786757, recent: 9.477611940298507\n",
      "Episode: 1027, steps: 11, reward: 11.0, average: 9.961089494163424, recent: 9.477611940298507\n",
      "Episode: 1028, steps: 9, reward: 9.0, average: 9.960155490767736, recent: 9.477611940298507\n",
      "Episode: 1029, steps: 11, reward: 11.0, average: 9.96116504854369, recent: 9.482587064676617\n",
      "Episode: 1030, steps: 10, reward: 10.0, average: 9.961202715809893, recent: 9.482587064676617\n",
      "loss:  52.512936\n",
      "Episode: 1031, steps: 10, reward: 10.0, average: 9.96124031007752, recent: 9.482587064676617\n",
      "Episode: 1032, steps: 8, reward: 8.0, average: 9.959341723136495, recent: 9.472636815920398\n",
      "Episode: 1033, steps: 8, reward: 8.0, average: 9.957446808510639, recent: 9.467661691542288\n",
      "Episode: 1034, steps: 10, reward: 10.0, average: 9.957487922705313, recent: 9.472636815920398\n",
      "Episode: 1035, steps: 9, reward: 9.0, average: 9.956563706563706, recent: 9.477611940298507\n",
      "Episode: 1036, steps: 11, reward: 11.0, average: 9.957569913211186, recent: 9.487562189054726\n",
      "Episode: 1037, steps: 10, reward: 10.0, average: 9.957610789980732, recent: 9.487562189054726\n",
      "Episode: 1038, steps: 9, reward: 9.0, average: 9.956689124157844, recent: 9.482587064676617\n",
      "Episode: 1039, steps: 9, reward: 9.0, average: 9.955769230769231, recent: 9.477611940298507\n",
      "Episode: 1040, steps: 8, reward: 8.0, average: 9.953890489913544, recent: 9.467661691542288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  22.955563\n",
      "Episode: 1041, steps: 9, reward: 9.0, average: 9.952975047984644, recent: 9.457711442786069\n",
      "Episode: 1042, steps: 8, reward: 8.0, average: 9.951102588686481, recent: 9.447761194029852\n",
      "Episode: 1043, steps: 10, reward: 10.0, average: 9.951149425287356, recent: 9.45273631840796\n",
      "Episode: 1044, steps: 10, reward: 10.0, average: 9.951196172248803, recent: 9.45273631840796\n",
      "Episode: 1045, steps: 10, reward: 10.0, average: 9.951242829827915, recent: 9.462686567164178\n",
      "Episode: 1046, steps: 10, reward: 10.0, average: 9.951289398280803, recent: 9.472636815920398\n",
      "Episode: 1047, steps: 10, reward: 10.0, average: 9.951335877862595, recent: 9.477611940298507\n",
      "Episode: 1048, steps: 10, reward: 10.0, average: 9.951382268827455, recent: 9.482587064676617\n",
      "Episode: 1049, steps: 9, reward: 9.0, average: 9.950476190476191, recent: 9.482587064676617\n",
      "Episode: 1050, steps: 10, reward: 10.0, average: 9.950523311132255, recent: 9.477611940298507\n",
      "loss:  16.956818\n",
      "Episode: 1051, steps: 9, reward: 9.0, average: 9.949619771863118, recent: 9.477611940298507\n",
      "Episode: 1052, steps: 10, reward: 10.0, average: 9.949667616334283, recent: 9.477611940298507\n",
      "Episode: 1053, steps: 9, reward: 9.0, average: 9.94876660341556, recent: 9.477611940298507\n",
      "Episode: 1054, steps: 9, reward: 9.0, average: 9.947867298578199, recent: 9.477611940298507\n",
      "Episode: 1055, steps: 8, reward: 8.0, average: 9.946022727272727, recent: 9.467661691542288\n",
      "Episode: 1056, steps: 9, reward: 9.0, average: 9.945127719962157, recent: 9.467661691542288\n",
      "Episode: 1057, steps: 8, reward: 8.0, average: 9.943289224952741, recent: 9.457711442786069\n",
      "Episode: 1058, steps: 10, reward: 10.0, average: 9.943342776203966, recent: 9.457711442786069\n",
      "Episode: 1059, steps: 10, reward: 10.0, average: 9.943396226415095, recent: 9.467661691542288\n",
      "Episode: 1060, steps: 10, reward: 10.0, average: 9.943449575871819, recent: 9.467661691542288\n",
      "loss:  4.3808002\n",
      "Episode: 1061, steps: 9, reward: 9.0, average: 9.94256120527307, recent: 9.457711442786069\n",
      "Episode: 1062, steps: 10, reward: 10.0, average: 9.942615239887113, recent: 9.457711442786069\n",
      "Episode: 1063, steps: 9, reward: 9.0, average: 9.941729323308271, recent: 9.45273631840796\n",
      "Episode: 1064, steps: 9, reward: 9.0, average: 9.940845070422535, recent: 9.447761194029852\n",
      "Episode: 1065, steps: 8, reward: 8.0, average: 9.939024390243903, recent: 9.442786069651742\n",
      "Episode: 1066, steps: 10, reward: 10.0, average: 9.939081537019682, recent: 9.432835820895523\n",
      "Episode: 1067, steps: 9, reward: 9.0, average: 9.938202247191011, recent: 9.432835820895523\n",
      "Episode: 1068, steps: 9, reward: 9.0, average: 9.937324602432179, recent: 9.427860696517413\n",
      "Episode: 1069, steps: 10, reward: 10.0, average: 9.937383177570094, recent: 9.432835820895523\n",
      "Episode: 1070, steps: 8, reward: 8.0, average: 9.935574229691877, recent: 9.412935323383085\n",
      "loss:  45.089893\n",
      "Episode: 1071, steps: 10, reward: 10.0, average: 9.935634328358208, recent: 9.417910447761194\n",
      "Episode: 1072, steps: 10, reward: 10.0, average: 9.93569431500466, recent: 9.422885572139304\n",
      "Episode: 1073, steps: 10, reward: 10.0, average: 9.935754189944134, recent: 9.432835820895523\n",
      "Episode: 1074, steps: 9, reward: 9.0, average: 9.934883720930232, recent: 9.427860696517413\n",
      "Episode: 1075, steps: 8, reward: 8.0, average: 9.933085501858736, recent: 9.422885572139304\n",
      "Episode: 1076, steps: 8, reward: 8.0, average: 9.931290622098421, recent: 9.417910447761194\n",
      "Episode: 1077, steps: 9, reward: 9.0, average: 9.930426716141001, recent: 9.412935323383085\n",
      "Episode: 1078, steps: 9, reward: 9.0, average: 9.929564411492123, recent: 9.407960199004975\n",
      "Episode: 1079, steps: 10, reward: 10.0, average: 9.92962962962963, recent: 9.412935323383085\n",
      "Episode: 1080, steps: 9, reward: 9.0, average: 9.92876965772433, recent: 9.407960199004975\n",
      "loss:  48.078926\n",
      "Episode: 1081, steps: 9, reward: 9.0, average: 9.927911275415896, recent: 9.402985074626866\n",
      "Episode: 1082, steps: 10, reward: 10.0, average: 9.92797783933518, recent: 9.407960199004975\n",
      "Episode: 1083, steps: 9, reward: 9.0, average: 9.927121771217712, recent: 9.407960199004975\n",
      "Episode: 1084, steps: 9, reward: 9.0, average: 9.926267281105991, recent: 9.402985074626866\n",
      "Episode: 1085, steps: 9, reward: 9.0, average: 9.925414364640885, recent: 9.402985074626866\n",
      "Episode: 1086, steps: 11, reward: 11.0, average: 9.926402943882245, recent: 9.407960199004975\n",
      "Episode: 1087, steps: 9, reward: 9.0, average: 9.925551470588236, recent: 9.402985074626866\n",
      "Episode: 1088, steps: 10, reward: 10.0, average: 9.925619834710744, recent: 9.407960199004975\n",
      "Episode: 1089, steps: 10, reward: 10.0, average: 9.925688073394495, recent: 9.412935323383085\n",
      "Episode: 1090, steps: 9, reward: 9.0, average: 9.924839596700275, recent: 9.412935323383085\n",
      "loss:  7.2343097\n",
      "Episode: 1091, steps: 9, reward: 9.0, average: 9.923992673992673, recent: 9.412935323383085\n",
      "Episode: 1092, steps: 8, reward: 8.0, average: 9.922232387923147, recent: 9.402985074626866\n",
      "Episode: 1093, steps: 10, reward: 10.0, average: 9.922303473491773, recent: 9.407960199004975\n",
      "Episode: 1094, steps: 9, reward: 9.0, average: 9.921461187214613, recent: 9.407960199004975\n",
      "Episode: 1095, steps: 10, reward: 10.0, average: 9.921532846715328, recent: 9.407960199004975\n",
      "Episode: 1096, steps: 10, reward: 10.0, average: 9.921604375569736, recent: 9.412935323383085\n",
      "Episode: 1097, steps: 11, reward: 11.0, average: 9.922586520947176, recent: 9.427860696517413\n",
      "Episode: 1098, steps: 12, reward: 12.0, average: 9.924476797088262, recent: 9.437810945273633\n",
      "Episode: 1099, steps: 9, reward: 9.0, average: 9.923636363636364, recent: 9.432835820895523\n",
      "Episode: 1100, steps: 8, reward: 8.0, average: 9.92188919164396, recent: 9.422885572139304\n",
      "loss:  0.8322284\n",
      "Episode: 1101, steps: 8, reward: 8.0, average: 9.920145190562613, recent: 9.417910447761194\n",
      "Episode: 1102, steps: 10, reward: 10.0, average: 9.920217588395285, recent: 9.417910447761194\n",
      "Episode: 1103, steps: 9, reward: 9.0, average: 9.919384057971014, recent: 9.417910447761194\n",
      "Episode: 1104, steps: 9, reward: 9.0, average: 9.918552036199095, recent: 9.412935323383085\n",
      "Episode: 1105, steps: 10, reward: 10.0, average: 9.91862567811935, recent: 9.422885572139304\n",
      "Episode: 1106, steps: 10, reward: 10.0, average: 9.91869918699187, recent: 9.427860696517413\n",
      "Episode: 1107, steps: 9, reward: 9.0, average: 9.917870036101084, recent: 9.422885572139304\n",
      "Episode: 1108, steps: 10, reward: 10.0, average: 9.917944093778178, recent: 9.427860696517413\n",
      "Episode: 1109, steps: 11, reward: 11.0, average: 9.91891891891892, recent: 9.432835820895523\n",
      "Episode: 1110, steps: 9, reward: 9.0, average: 9.918091809180918, recent: 9.422885572139304\n",
      "loss:  0.5648955\n",
      "Episode: 1111, steps: 11, reward: 11.0, average: 9.91906474820144, recent: 9.432835820895523\n",
      "Episode: 1112, steps: 11, reward: 11.0, average: 9.920035938903863, recent: 9.432835820895523\n",
      "Episode: 1113, steps: 9, reward: 9.0, average: 9.919210053859963, recent: 9.427860696517413\n",
      "Episode: 1114, steps: 13, reward: 13.0, average: 9.921973094170404, recent: 9.442786069651742\n",
      "Episode: 1115, steps: 10, reward: 10.0, average: 9.922043010752688, recent: 9.447761194029852\n",
      "Episode: 1116, steps: 9, reward: 9.0, average: 9.921217547000895, recent: 9.447761194029852\n",
      "Episode: 1117, steps: 9, reward: 9.0, average: 9.920393559928444, recent: 9.442786069651742\n",
      "Episode: 1118, steps: 9, reward: 9.0, average: 9.919571045576408, recent: 9.437810945273633\n",
      "Episode: 1119, steps: 9, reward: 9.0, average: 9.91875, recent: 9.432835820895523\n",
      "Episode: 1120, steps: 9, reward: 9.0, average: 9.91793041926851, recent: 9.437810945273633\n",
      "loss:  2643.8977\n",
      "Episode: 1121, steps: 9, reward: 9.0, average: 9.917112299465241, recent: 9.437810945273633\n",
      "Episode: 1122, steps: 10, reward: 10.0, average: 9.917186108637578, recent: 9.442786069651742\n",
      "Episode: 1123, steps: 8, reward: 8.0, average: 9.915480427046264, recent: 9.432835820895523\n",
      "Episode: 1124, steps: 9, reward: 9.0, average: 9.914666666666667, recent: 9.437810945273633\n",
      "Episode: 1125, steps: 11, reward: 11.0, average: 9.91563055062167, recent: 9.447761194029852\n",
      "Episode: 1126, steps: 10, reward: 10.0, average: 9.915705412599822, recent: 9.457711442786069\n",
      "Episode: 1127, steps: 10, reward: 10.0, average: 9.915780141843971, recent: 9.457711442786069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1128, steps: 9, reward: 9.0, average: 9.91496899911426, recent: 9.457711442786069\n",
      "Episode: 1129, steps: 9, reward: 9.0, average: 9.914159292035398, recent: 9.45273631840796\n",
      "Episode: 1130, steps: 8, reward: 8.0, average: 9.912466843501326, recent: 9.447761194029852\n",
      "loss:  518.3987\n",
      "Episode: 1131, steps: 11, reward: 11.0, average: 9.913427561837455, recent: 9.457711442786069\n",
      "Episode: 1132, steps: 10, reward: 10.0, average: 9.913503971756398, recent: 9.457711442786069\n",
      "Episode: 1133, steps: 11, reward: 11.0, average: 9.914462081128748, recent: 9.467661691542288\n",
      "Episode: 1134, steps: 10, reward: 10.0, average: 9.91453744493392, recent: 9.472636815920398\n",
      "Episode: 1135, steps: 10, reward: 10.0, average: 9.914612676056338, recent: 9.467661691542288\n",
      "Episode: 1136, steps: 9, reward: 9.0, average: 9.913808267370273, recent: 9.467661691542288\n",
      "Episode: 1137, steps: 10, reward: 10.0, average: 9.913884007029877, recent: 9.467661691542288\n",
      "Episode: 1138, steps: 10, reward: 10.0, average: 9.913959613696225, recent: 9.467661691542288\n",
      "Episode: 1139, steps: 10, reward: 10.0, average: 9.914035087719299, recent: 9.477611940298507\n",
      "Episode: 1140, steps: 10, reward: 10.0, average: 9.914110429447852, recent: 9.482587064676617\n",
      "loss:  276.18518\n",
      "Episode: 1141, steps: 10, reward: 10.0, average: 9.914185639229421, recent: 9.487562189054726\n",
      "Episode: 1142, steps: 9, reward: 9.0, average: 9.913385826771654, recent: 9.487562189054726\n",
      "Episode: 1143, steps: 9, reward: 9.0, average: 9.912587412587413, recent: 9.482587064676617\n",
      "Episode: 1144, steps: 10, reward: 10.0, average: 9.912663755458516, recent: 9.482587064676617\n",
      "Episode: 1145, steps: 9, reward: 9.0, average: 9.911867364746946, recent: 9.477611940298507\n",
      "Episode: 1146, steps: 8, reward: 8.0, average: 9.910200523103748, recent: 9.472636815920398\n",
      "Episode: 1147, steps: 11, reward: 11.0, average: 9.911149825783973, recent: 9.487562189054726\n",
      "Episode: 1148, steps: 9, reward: 9.0, average: 9.91035683202785, recent: 9.492537313432836\n",
      "Episode: 1149, steps: 9, reward: 9.0, average: 9.909565217391304, recent: 9.487562189054726\n",
      "Episode: 1150, steps: 9, reward: 9.0, average: 9.908774978279757, recent: 9.477611940298507\n",
      "loss:  70.44129\n",
      "Episode: 1151, steps: 11, reward: 11.0, average: 9.909722222222221, recent: 9.482587064676617\n",
      "Episode: 1152, steps: 10, reward: 10.0, average: 9.909800520381614, recent: 9.482587064676617\n",
      "Episode: 1153, steps: 9, reward: 9.0, average: 9.909012131715771, recent: 9.482587064676617\n",
      "Episode: 1154, steps: 10, reward: 10.0, average: 9.909090909090908, recent: 9.487562189054726\n",
      "Episode: 1155, steps: 10, reward: 10.0, average: 9.90916955017301, recent: 9.487562189054726\n",
      "Episode: 1156, steps: 10, reward: 10.0, average: 9.909248055315471, recent: 9.487562189054726\n",
      "Episode: 1157, steps: 11, reward: 11.0, average: 9.910189982728843, recent: 9.497512437810945\n",
      "Episode: 1158, steps: 9, reward: 9.0, average: 9.909404659188956, recent: 9.502487562189055\n",
      "Episode: 1159, steps: 9, reward: 9.0, average: 9.908620689655173, recent: 9.497512437810945\n",
      "Episode: 1160, steps: 11, reward: 11.0, average: 9.909560723514211, recent: 9.502487562189055\n",
      "loss:  16.007607\n",
      "Episode: 1161, steps: 8, reward: 8.0, average: 9.907917383820998, recent: 9.492537313432836\n",
      "Episode: 1162, steps: 9, reward: 9.0, average: 9.90713671539123, recent: 9.487562189054726\n",
      "Episode: 1163, steps: 9, reward: 9.0, average: 9.90635738831615, recent: 9.492537313432836\n",
      "Episode: 1164, steps: 10, reward: 10.0, average: 9.906437768240343, recent: 9.492537313432836\n",
      "Episode: 1165, steps: 10, reward: 10.0, average: 9.906518010291595, recent: 9.497512437810945\n",
      "Episode: 1166, steps: 10, reward: 10.0, average: 9.906598114824336, recent: 9.502487562189055\n",
      "Episode: 1167, steps: 10, reward: 10.0, average: 9.906678082191782, recent: 9.502487562189055\n",
      "Episode: 1168, steps: 9, reward: 9.0, average: 9.905902480752781, recent: 9.502487562189055\n",
      "Episode: 1169, steps: 9, reward: 9.0, average: 9.905128205128205, recent: 9.502487562189055\n",
      "Episode: 1170, steps: 9, reward: 9.0, average: 9.904355251921436, recent: 9.497512437810945\n",
      "loss:  65.20905\n",
      "Episode: 1171, steps: 8, reward: 8.0, average: 9.902730375426621, recent: 9.487562189054726\n",
      "Episode: 1172, steps: 9, reward: 9.0, average: 9.901960784313726, recent: 9.482587064676617\n",
      "Episode: 1173, steps: 10, reward: 10.0, average: 9.902044293015333, recent: 9.487562189054726\n",
      "Episode: 1174, steps: 9, reward: 9.0, average: 9.901276595744681, recent: 9.492537313432836\n",
      "Episode: 1175, steps: 10, reward: 10.0, average: 9.901360544217686, recent: 9.487562189054726\n",
      "Episode: 1176, steps: 11, reward: 11.0, average: 9.90229396771453, recent: 9.492537313432836\n",
      "Episode: 1177, steps: 9, reward: 9.0, average: 9.901528013582343, recent: 9.492537313432836\n",
      "Episode: 1178, steps: 9, reward: 9.0, average: 9.900763358778626, recent: 9.487562189054726\n",
      "Episode: 1179, steps: 9, reward: 9.0, average: 9.9, recent: 9.482587064676617\n",
      "Episode: 1180, steps: 9, reward: 9.0, average: 9.899237933954277, recent: 9.477611940298507\n",
      "loss:  206.11053\n",
      "Episode: 1181, steps: 9, reward: 9.0, average: 9.898477157360405, recent: 9.472636815920398\n",
      "Episode: 1182, steps: 8, reward: 8.0, average: 9.89687235841082, recent: 9.472636815920398\n",
      "Episode: 1183, steps: 10, reward: 10.0, average: 9.89695945945946, recent: 9.482587064676617\n",
      "Episode: 1184, steps: 9, reward: 9.0, average: 9.896202531645569, recent: 9.477611940298507\n",
      "Episode: 1185, steps: 10, reward: 10.0, average: 9.896290050590219, recent: 9.477611940298507\n",
      "Episode: 1186, steps: 10, reward: 10.0, average: 9.896377422072451, recent: 9.477611940298507\n",
      "Episode: 1187, steps: 8, reward: 8.0, average: 9.894781144781145, recent: 9.467661691542288\n",
      "Episode: 1188, steps: 10, reward: 10.0, average: 9.894869638351556, recent: 9.472636815920398\n",
      "Episode: 1189, steps: 8, reward: 8.0, average: 9.89327731092437, recent: 9.462686567164178\n",
      "Episode: 1190, steps: 8, reward: 8.0, average: 9.891687657430731, recent: 9.45273631840796\n",
      "loss:  3172.5908\n",
      "Episode: 1191, steps: 9, reward: 9.0, average: 9.890939597315436, recent: 9.457711442786069\n",
      "Episode: 1192, steps: 8, reward: 8.0, average: 9.889354568315172, recent: 9.447761194029852\n",
      "Episode: 1193, steps: 9, reward: 9.0, average: 9.88860971524288, recent: 9.447761194029852\n",
      "Episode: 1194, steps: 9, reward: 9.0, average: 9.88786610878661, recent: 9.447761194029852\n",
      "Episode: 1195, steps: 10, reward: 10.0, average: 9.887959866220736, recent: 9.45273631840796\n",
      "Episode: 1196, steps: 9, reward: 9.0, average: 9.887218045112782, recent: 9.45273631840796\n",
      "Episode: 1197, steps: 8, reward: 8.0, average: 9.885642737896495, recent: 9.447761194029852\n",
      "Episode: 1198, steps: 9, reward: 9.0, average: 9.884904086738949, recent: 9.442786069651742\n",
      "Episode: 1199, steps: 10, reward: 10.0, average: 9.885, recent: 9.447761194029852\n",
      "Episode: 1200, steps: 10, reward: 10.0, average: 9.885095753538717, recent: 9.45273631840796\n",
      "loss:  2660.8074\n",
      "Episode: 1201, steps: 9, reward: 9.0, average: 9.884359400998337, recent: 9.447761194029852\n",
      "Episode: 1202, steps: 10, reward: 10.0, average: 9.884455527847049, recent: 9.442786069651742\n",
      "Episode: 1203, steps: 9, reward: 9.0, average: 9.883720930232558, recent: 9.442786069651742\n",
      "Episode: 1204, steps: 10, reward: 10.0, average: 9.883817427385893, recent: 9.442786069651742\n",
      "Episode: 1205, steps: 8, reward: 8.0, average: 9.882255389718077, recent: 9.432835820895523\n",
      "Episode: 1206, steps: 9, reward: 9.0, average: 9.88152444076222, recent: 9.427860696517413\n",
      "Episode: 1207, steps: 9, reward: 9.0, average: 9.880794701986755, recent: 9.422885572139304\n",
      "Episode: 1208, steps: 10, reward: 10.0, average: 9.88089330024814, recent: 9.427860696517413\n",
      "Episode: 1209, steps: 9, reward: 9.0, average: 9.880165289256198, recent: 9.422885572139304\n",
      "Episode: 1210, steps: 9, reward: 9.0, average: 9.87943848059455, recent: 9.417910447761194\n",
      "loss:  58.411842\n",
      "Episode: 1211, steps: 8, reward: 8.0, average: 9.877887788778878, recent: 9.417910447761194\n",
      "Episode: 1212, steps: 9, reward: 9.0, average: 9.877164056059357, recent: 9.417910447761194\n",
      "Episode: 1213, steps: 9, reward: 9.0, average: 9.876441515650741, recent: 9.417910447761194\n",
      "Episode: 1214, steps: 10, reward: 10.0, average: 9.876543209876543, recent: 9.427860696517413\n",
      "Episode: 1215, steps: 9, reward: 9.0, average: 9.875822368421053, recent: 9.422885572139304\n",
      "Episode: 1216, steps: 9, reward: 9.0, average: 9.875102711585868, recent: 9.417910447761194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1217, steps: 9, reward: 9.0, average: 9.874384236453203, recent: 9.422885572139304\n",
      "Episode: 1218, steps: 9, reward: 9.0, average: 9.873666940114848, recent: 9.427860696517413\n",
      "Episode: 1219, steps: 9, reward: 9.0, average: 9.87295081967213, recent: 9.422885572139304\n",
      "Episode: 1220, steps: 10, reward: 10.0, average: 9.873054873054873, recent: 9.422885572139304\n",
      "loss:  2326.4912\n",
      "Episode: 1221, steps: 9, reward: 9.0, average: 9.872340425531915, recent: 9.422885572139304\n",
      "Episode: 1222, steps: 10, reward: 10.0, average: 9.87244480784955, recent: 9.427860696517413\n",
      "Episode: 1223, steps: 10, reward: 10.0, average: 9.872549019607844, recent: 9.427860696517413\n",
      "Episode: 1224, steps: 9, reward: 9.0, average: 9.871836734693877, recent: 9.417910447761194\n",
      "Episode: 1225, steps: 8, reward: 8.0, average: 9.870309951060358, recent: 9.412935323383085\n",
      "Episode: 1226, steps: 9, reward: 9.0, average: 9.86960065199674, recent: 9.407960199004975\n",
      "Episode: 1227, steps: 9, reward: 9.0, average: 9.868892508143322, recent: 9.402985074626866\n",
      "Episode: 1228, steps: 10, reward: 10.0, average: 9.868999186330349, recent: 9.398009950248756\n",
      "Episode: 1229, steps: 9, reward: 9.0, average: 9.86829268292683, recent: 9.398009950248756\n",
      "Episode: 1230, steps: 10, reward: 10.0, average: 9.868399675060926, recent: 9.393034825870647\n",
      "loss:  2400.1365\n",
      "Episode: 1231, steps: 9, reward: 9.0, average: 9.867694805194805, recent: 9.388059701492537\n",
      "Episode: 1232, steps: 9, reward: 9.0, average: 9.86699107866991, recent: 9.383084577114428\n",
      "Episode: 1233, steps: 10, reward: 10.0, average: 9.86709886547812, recent: 9.393034825870647\n",
      "Episode: 1234, steps: 8, reward: 8.0, average: 9.865587044534413, recent: 9.393034825870647\n",
      "Episode: 1235, steps: 10, reward: 10.0, average: 9.86569579288026, recent: 9.393034825870647\n",
      "Episode: 1236, steps: 9, reward: 9.0, average: 9.864995957962813, recent: 9.393034825870647\n",
      "Episode: 1237, steps: 8, reward: 8.0, average: 9.863489499192246, recent: 9.378109452736318\n",
      "Episode: 1238, steps: 9, reward: 9.0, average: 9.862792574656982, recent: 9.373134328358208\n",
      "Episode: 1239, steps: 11, reward: 11.0, average: 9.863709677419354, recent: 9.383084577114428\n",
      "Episode: 1240, steps: 10, reward: 10.0, average: 9.8638195004029, recent: 9.388059701492537\n",
      "loss:  277.63797\n",
      "Episode: 1241, steps: 10, reward: 10.0, average: 9.863929146537842, recent: 9.398009950248756\n",
      "Episode: 1242, steps: 10, reward: 10.0, average: 9.864038616251005, recent: 9.402985074626866\n",
      "Episode: 1243, steps: 8, reward: 8.0, average: 9.862540192926046, recent: 9.402985074626866\n",
      "Episode: 1244, steps: 9, reward: 9.0, average: 9.861847389558234, recent: 9.398009950248756\n",
      "Episode: 1245, steps: 9, reward: 9.0, average: 9.86115569823435, recent: 9.393034825870647\n",
      "Episode: 1246, steps: 9, reward: 9.0, average: 9.86046511627907, recent: 9.388059701492537\n",
      "Episode: 1247, steps: 9, reward: 9.0, average: 9.85977564102564, recent: 9.383084577114428\n",
      "Episode: 1248, steps: 12, reward: 12.0, average: 9.861489191353083, recent: 9.393034825870647\n",
      "Episode: 1249, steps: 10, reward: 10.0, average: 9.8616, recent: 9.393034825870647\n",
      "Episode: 1250, steps: 10, reward: 10.0, average: 9.861710631494804, recent: 9.398009950248756\n",
      "loss:  1.4025426\n",
      "Episode: 1251, steps: 10, reward: 10.0, average: 9.861821086261982, recent: 9.398009950248756\n",
      "Episode: 1252, steps: 9, reward: 9.0, average: 9.861133280127694, recent: 9.398009950248756\n",
      "Episode: 1253, steps: 9, reward: 9.0, average: 9.860446570972886, recent: 9.393034825870647\n",
      "Episode: 1254, steps: 9, reward: 9.0, average: 9.859760956175299, recent: 9.393034825870647\n",
      "Episode: 1255, steps: 10, reward: 10.0, average: 9.859872611464969, recent: 9.398009950248756\n",
      "Episode: 1256, steps: 10, reward: 10.0, average: 9.859984089101035, recent: 9.407960199004975\n",
      "Episode: 1257, steps: 9, reward: 9.0, average: 9.859300476947535, recent: 9.407960199004975\n",
      "Episode: 1258, steps: 10, reward: 10.0, average: 9.859412231930103, recent: 9.417910447761194\n",
      "Episode: 1259, steps: 11, reward: 11.0, average: 9.86031746031746, recent: 9.422885572139304\n",
      "Episode: 1260, steps: 9, reward: 9.0, average: 9.859635210150675, recent: 9.417910447761194\n",
      "loss:  469.3611\n",
      "Episode: 1261, steps: 9, reward: 9.0, average: 9.858954041204438, recent: 9.412935323383085\n",
      "Episode: 1262, steps: 10, reward: 10.0, average: 9.859065716547901, recent: 9.417910447761194\n",
      "Episode: 1263, steps: 10, reward: 10.0, average: 9.859177215189874, recent: 9.417910447761194\n",
      "Episode: 1264, steps: 8, reward: 8.0, average: 9.857707509881424, recent: 9.412935323383085\n",
      "Episode: 1265, steps: 9, reward: 9.0, average: 9.857030015797788, recent: 9.412935323383085\n",
      "Episode: 1266, steps: 9, reward: 9.0, average: 9.856353591160222, recent: 9.417910447761194\n",
      "Episode: 1267, steps: 10, reward: 10.0, average: 9.85646687697161, recent: 9.417910447761194\n",
      "Episode: 1268, steps: 10, reward: 10.0, average: 9.85657998423956, recent: 9.422885572139304\n",
      "Episode: 1269, steps: 10, reward: 10.0, average: 9.856692913385826, recent: 9.427860696517413\n",
      "Episode: 1270, steps: 9, reward: 9.0, average: 9.856018882769472, recent: 9.422885572139304\n",
      "loss:  2.4646835\n",
      "Episode: 1271, steps: 10, reward: 10.0, average: 9.856132075471699, recent: 9.432835820895523\n",
      "Episode: 1272, steps: 10, reward: 10.0, average: 9.856245090337785, recent: 9.432835820895523\n",
      "Episode: 1273, steps: 9, reward: 9.0, average: 9.85557299843014, recent: 9.427860696517413\n",
      "Episode: 1274, steps: 10, reward: 10.0, average: 9.855686274509804, recent: 9.427860696517413\n",
      "Episode: 1275, steps: 10, reward: 10.0, average: 9.855799373040753, recent: 9.432835820895523\n",
      "Episode: 1276, steps: 8, reward: 8.0, average: 9.854346123727487, recent: 9.432835820895523\n",
      "Episode: 1277, steps: 9, reward: 9.0, average: 9.853677621283255, recent: 9.437810945273633\n",
      "Episode: 1278, steps: 9, reward: 9.0, average: 9.853010164190774, recent: 9.437810945273633\n",
      "Episode: 1279, steps: 11, reward: 11.0, average: 9.85390625, recent: 9.447761194029852\n",
      "Episode: 1280, steps: 10, reward: 10.0, average: 9.854020296643247, recent: 9.447761194029852\n",
      "loss:  71.931435\n",
      "Episode: 1281, steps: 10, reward: 10.0, average: 9.854134165366615, recent: 9.45273631840796\n",
      "Episode: 1282, steps: 9, reward: 9.0, average: 9.853468433359314, recent: 9.45273631840796\n",
      "Episode: 1283, steps: 9, reward: 9.0, average: 9.852803738317757, recent: 9.447761194029852\n",
      "Episode: 1284, steps: 9, reward: 9.0, average: 9.852140077821012, recent: 9.447761194029852\n",
      "Episode: 1285, steps: 11, reward: 11.0, average: 9.85303265940902, recent: 9.457711442786069\n",
      "Episode: 1286, steps: 10, reward: 10.0, average: 9.853146853146853, recent: 9.462686567164178\n",
      "Episode: 1287, steps: 9, reward: 9.0, average: 9.852484472049689, recent: 9.45273631840796\n",
      "Episode: 1288, steps: 8, reward: 8.0, average: 9.851047323506593, recent: 9.447761194029852\n",
      "Episode: 1289, steps: 9, reward: 9.0, average: 9.850387596899225, recent: 9.442786069651742\n",
      "Episode: 1290, steps: 11, reward: 11.0, average: 9.851278079008521, recent: 9.447761194029852\n",
      "loss:  216.8617\n",
      "Episode: 1291, steps: 10, reward: 10.0, average: 9.85139318885449, recent: 9.45273631840796\n",
      "Episode: 1292, steps: 9, reward: 9.0, average: 9.850734725444703, recent: 9.45273631840796\n",
      "Episode: 1293, steps: 9, reward: 9.0, average: 9.850077279752705, recent: 9.457711442786069\n",
      "Episode: 1294, steps: 10, reward: 10.0, average: 9.85019305019305, recent: 9.457711442786069\n",
      "Episode: 1295, steps: 10, reward: 10.0, average: 9.850308641975309, recent: 9.462686567164178\n",
      "Episode: 1296, steps: 9, reward: 9.0, average: 9.84965304548959, recent: 9.457711442786069\n",
      "Episode: 1297, steps: 10, reward: 10.0, average: 9.849768875192604, recent: 9.457711442786069\n",
      "Episode: 1298, steps: 10, reward: 10.0, average: 9.849884526558892, recent: 9.45273631840796\n",
      "Episode: 1299, steps: 10, reward: 10.0, average: 9.85, recent: 9.442786069651742\n",
      "Episode: 1300, steps: 9, reward: 9.0, average: 9.84934665641814, recent: 9.442786069651742\n",
      "loss:  1.475589\n",
      "Episode: 1301, steps: 10, reward: 10.0, average: 9.849462365591398, recent: 9.45273631840796\n",
      "Episode: 1302, steps: 10, reward: 10.0, average: 9.8495778971604, recent: 9.462686567164178\n",
      "Episode: 1303, steps: 12, reward: 12.0, average: 9.85122699386503, recent: 9.472636815920398\n",
      "Episode: 1304, steps: 9, reward: 9.0, average: 9.850574712643677, recent: 9.472636815920398\n",
      "Episode: 1305, steps: 9, reward: 9.0, average: 9.849923430321592, recent: 9.472636815920398\n",
      "Episode: 1306, steps: 9, reward: 9.0, average: 9.849273144605968, recent: 9.467661691542288\n",
      "Episode: 1307, steps: 8, reward: 8.0, average: 9.847859327217126, recent: 9.457711442786069\n",
      "Episode: 1308, steps: 9, reward: 9.0, average: 9.847211611917494, recent: 9.457711442786069\n",
      "Episode: 1309, steps: 9, reward: 9.0, average: 9.846564885496184, recent: 9.45273631840796\n",
      "Episode: 1310, steps: 11, reward: 11.0, average: 9.84744469870328, recent: 9.45273631840796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  173.9977\n",
      "Episode: 1311, steps: 11, reward: 11.0, average: 9.848323170731707, recent: 9.462686567164178\n",
      "Episode: 1312, steps: 10, reward: 10.0, average: 9.848438690022848, recent: 9.457711442786069\n",
      "Episode: 1313, steps: 10, reward: 10.0, average: 9.84855403348554, recent: 9.45273631840796\n",
      "Episode: 1314, steps: 9, reward: 9.0, average: 9.847908745247148, recent: 9.45273631840796\n",
      "Episode: 1315, steps: 10, reward: 10.0, average: 9.848024316109422, recent: 9.437810945273633\n",
      "Episode: 1316, steps: 11, reward: 11.0, average: 9.848899012908124, recent: 9.442786069651742\n",
      "Episode: 1317, steps: 10, reward: 10.0, average: 9.849013657056146, recent: 9.447761194029852\n",
      "Episode: 1318, steps: 10, reward: 10.0, average: 9.84912812736922, recent: 9.45273631840796\n",
      "Episode: 1319, steps: 10, reward: 10.0, average: 9.849242424242425, recent: 9.457711442786069\n",
      "Episode: 1320, steps: 12, reward: 12.0, average: 9.850870552611658, recent: 9.472636815920398\n",
      "loss:  1788.2699\n",
      "Episode: 1321, steps: 9, reward: 9.0, average: 9.850226928895612, recent: 9.472636815920398\n",
      "Episode: 1322, steps: 10, reward: 10.0, average: 9.850340136054422, recent: 9.477611940298507\n",
      "Episode: 1323, steps: 9, reward: 9.0, average: 9.849697885196374, recent: 9.472636815920398\n",
      "Episode: 1324, steps: 10, reward: 10.0, average: 9.849811320754718, recent: 9.482587064676617\n",
      "Episode: 1325, steps: 10, reward: 10.0, average: 9.849924585218703, recent: 9.487562189054726\n",
      "Episode: 1326, steps: 9, reward: 9.0, average: 9.849284099472495, recent: 9.477611940298507\n",
      "Episode: 1327, steps: 10, reward: 10.0, average: 9.849397590361447, recent: 9.477611940298507\n",
      "Episode: 1328, steps: 10, reward: 10.0, average: 9.849510910458992, recent: 9.477611940298507\n",
      "Episode: 1329, steps: 8, reward: 8.0, average: 9.84812030075188, recent: 9.472636815920398\n",
      "Episode: 1330, steps: 10, reward: 10.0, average: 9.84823441021788, recent: 9.477611940298507\n",
      "loss:  70.57436\n",
      "Episode: 1331, steps: 10, reward: 10.0, average: 9.848348348348349, recent: 9.487562189054726\n",
      "Episode: 1332, steps: 10, reward: 10.0, average: 9.848462115528882, recent: 9.482587064676617\n",
      "Episode: 1333, steps: 11, reward: 11.0, average: 9.849325337331335, recent: 9.487562189054726\n",
      "Episode: 1334, steps: 10, reward: 10.0, average: 9.84943820224719, recent: 9.482587064676617\n",
      "Episode: 1335, steps: 10, reward: 10.0, average: 9.849550898203592, recent: 9.482587064676617\n",
      "Episode: 1336, steps: 9, reward: 9.0, average: 9.848915482423337, recent: 9.477611940298507\n",
      "Episode: 1337, steps: 11, reward: 11.0, average: 9.849775784753364, recent: 9.487562189054726\n",
      "Episode: 1338, steps: 9, reward: 9.0, average: 9.849141150112024, recent: 9.482587064676617\n",
      "Episode: 1339, steps: 9, reward: 9.0, average: 9.848507462686568, recent: 9.477611940298507\n",
      "Episode: 1340, steps: 10, reward: 10.0, average: 9.84862043251305, recent: 9.477611940298507\n",
      "loss:  534.6388\n",
      "Episode: 1341, steps: 10, reward: 10.0, average: 9.848733233979136, recent: 9.477611940298507\n",
      "Episode: 1342, steps: 9, reward: 9.0, average: 9.848101265822784, recent: 9.472636815920398\n",
      "Episode: 1343, steps: 9, reward: 9.0, average: 9.847470238095237, recent: 9.472636815920398\n",
      "Episode: 1344, steps: 9, reward: 9.0, average: 9.846840148698885, recent: 9.472636815920398\n",
      "Episode: 1345, steps: 10, reward: 10.0, average: 9.846953937592868, recent: 9.472636815920398\n",
      "Episode: 1346, steps: 9, reward: 9.0, average: 9.846325167037861, recent: 9.472636815920398\n",
      "Episode: 1347, steps: 9, reward: 9.0, average: 9.845697329376854, recent: 9.477611940298507\n",
      "Episode: 1348, steps: 9, reward: 9.0, average: 9.845070422535212, recent: 9.467661691542288\n",
      "Episode: 1349, steps: 9, reward: 9.0, average: 9.844444444444445, recent: 9.467661691542288\n",
      "Episode: 1350, steps: 9, reward: 9.0, average: 9.84381939304219, recent: 9.467661691542288\n",
      "loss:  258.8487\n",
      "Episode: 1351, steps: 9, reward: 9.0, average: 9.84319526627219, recent: 9.467661691542288\n",
      "Episode: 1352, steps: 9, reward: 9.0, average: 9.842572062084257, recent: 9.457711442786069\n",
      "Episode: 1353, steps: 8, reward: 8.0, average: 9.841211225997046, recent: 9.447761194029852\n",
      "Episode: 1354, steps: 10, reward: 10.0, average: 9.841328413284133, recent: 9.45273631840796\n",
      "Episode: 1355, steps: 9, reward: 9.0, average: 9.84070796460177, recent: 9.447761194029852\n",
      "Episode: 1356, steps: 10, reward: 10.0, average: 9.840825350036846, recent: 9.447761194029852\n",
      "Episode: 1357, steps: 9, reward: 9.0, average: 9.84020618556701, recent: 9.442786069651742\n",
      "Episode: 1358, steps: 10, reward: 10.0, average: 9.840323767476086, recent: 9.437810945273633\n",
      "Episode: 1359, steps: 10, reward: 10.0, average: 9.840441176470588, recent: 9.442786069651742\n",
      "Episode: 1360, steps: 11, reward: 11.0, average: 9.841293166789125, recent: 9.45273631840796\n",
      "loss:  46.712128\n",
      "Episode: 1361, steps: 9, reward: 9.0, average: 9.840675477239355, recent: 9.442786069651742\n",
      "Episode: 1362, steps: 9, reward: 9.0, average: 9.840058694057227, recent: 9.447761194029852\n",
      "Episode: 1363, steps: 10, reward: 10.0, average: 9.840175953079179, recent: 9.45273631840796\n",
      "Episode: 1364, steps: 9, reward: 9.0, average: 9.83956043956044, recent: 9.45273631840796\n",
      "Episode: 1365, steps: 9, reward: 9.0, average: 9.838945827232797, recent: 9.447761194029852\n",
      "Episode: 1366, steps: 10, reward: 10.0, average: 9.8390636430139, recent: 9.447761194029852\n",
      "Episode: 1367, steps: 9, reward: 9.0, average: 9.838450292397662, recent: 9.442786069651742\n",
      "Episode: 1368, steps: 10, reward: 10.0, average: 9.838568298027758, recent: 9.442786069651742\n",
      "Episode: 1369, steps: 9, reward: 9.0, average: 9.837956204379562, recent: 9.442786069651742\n",
      "Episode: 1370, steps: 9, reward: 9.0, average: 9.837345003646973, recent: 9.442786069651742\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8cec1f2c9914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             sess.run([W1_.assign(W1), W2_.assign(W2), W3_.assign(W3), W4_.assign(W4), \\\n\u001b[0;32m---> 58\u001b[0;31m               b1_.assign(b1), b2_.assign(b2), b3_.assign(b3)])\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    607\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \"\"\"\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    279\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    280\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3288\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3291\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m   3292\u001b[0m                              compute_device=compute_device)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[0;31m# Initialize self._c_op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2127\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;34m\"\"\"The `Graph` that contains this operation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess : \n",
    "    sess.run(init)\n",
    "    sess.run([W1_.assign(W1), W2_.assign(W2), W3_.assign(W3), W4_.assign(W4), \\\n",
    "              b1_.assign(b1), b2_.assign(b2), b3_.assign(b3)])\n",
    "    \n",
    "    while np.mean(recent_rList) < 195 :\n",
    "        episode += 1\n",
    "        s = env.reset()\n",
    "        \n",
    "        if len(recent_rList) > 200 :\n",
    "            del recent_rList[0]\n",
    "            \n",
    "        e = 1./((episode/25) + 1)\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        \n",
    "        while not d and j < num_episodes :\n",
    "            j += 1\n",
    "            s_t = np.reshape(s, [1,INPUT])\n",
    "            \n",
    "            Q = sess.run(Q_, feed_dict={x: s_t, dropout: dp})\n",
    "            \n",
    "            if e > np.random.rand(1) :\n",
    "                a = env.action_space.sample()\n",
    "            else :\n",
    "                a = np.argmax(0)\n",
    "                \n",
    "            s1, r, d, _ = env.step(a)\n",
    "            REPLAYLIST.append([s_t, a, r, s1, d, j])\n",
    "            \n",
    "            if len(REPLAYLIST) > CAPACITY :\n",
    "                del REPLAYLIST[0]\n",
    "                \n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "        if episode%10 == 1 and len(REPLAYLIST) > MINIBATCH :\n",
    "            for sample in ran.sample(REPLAYLIST, REPLAY) :\n",
    "                s_t_r, a_r, r_r, s1_r, d_r, j_r = sample\n",
    "                \n",
    "                Q = sess.run(Q_, feed_dict={x: s_t_r, dropout: dp})\n",
    "                \n",
    "                if d_r :\n",
    "                    if j_r < env.spec.timestep_limit :\n",
    "                        Q[0, a_r] = -100\n",
    "                        \n",
    "                else :\n",
    "                    s1_t_r = np.reshape(s1_r, [1,INPUT])\n",
    "                    Q1 = sess.run(Q_r, feed_dict={x: s1_t_r})\n",
    "                    Q[0, a_r] = r_r + df*np.max(Q1)\n",
    "                    \n",
    "                _, loss_ = sess.run([train, loss], feed_dict={x: s_t_r, y: Q, dropout: dp})\n",
    "                \n",
    "            sess.run([W1_.assign(W1), W2_.assign(W2), W3_.assign(W3), W4_.assign(W4), \\\n",
    "              b1_.assign(b1), b2_.assign(b2), b3_.assign(b3)])\n",
    "            print(\"loss: \", loss_)\n",
    "            \n",
    "        recent_rList.append(rAll)\n",
    "        rList.append(rAll)\n",
    "        print(\"Episode: {}, steps: {}, reward: {}, average: {}, recent: {}\".format(episode, j, rAll, np.mean(rList), np.mean(recent_rList)))\n",
    "        \n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: \", save_path)\n",
    "    \n",
    "    rList = []\n",
    "    recent_rList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
